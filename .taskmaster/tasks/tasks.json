{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Initialize Project Repository and Dependencies",
        "description": "Set up the prime-directive repository structure and install all required dependencies using uv for Python 3.11+",
        "details": "Create repository structure exactly as specified: bin/, system/, core/, data/. Use `uv init prime-directive` then `uv add typer[all]>=0.12.0 sqlmodel>=0.0.22 watchdog>=5.0.2 rich>=13.9.0 requests>=2.32.0 pyyaml>=6.0.2`. Create pyproject.toml with [project.scripts]: pd=prime_directive.bin.pd:cli, pd-daemon=prime_directive.bin.pd_daemon:main. Initialize git and create .gitignore for data/ and __pycache__.",
        "testStrategy": "Run `uv sync` and verify `pd --help` shows Typer CLI. Check `tree prime-directive/` matches exact structure. `pytest --version` works.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement Registry Configuration Parser",
        "description": "Create system/registry.yaml parser that loads repository mappings with extended schema including editor_cmd",
        "details": "In core/registry.py: Load system/registry.yaml with schema {system: {editor_cmd: str='windsurf', ai_model: str='qwen2.5-coder', db_path: str}, repos: [{id: str, path: str, priority: int}]}. Use pydantic v2.9+ BaseModel for validation. Default editor_cmd='windsurf' (verified as VSCode fork with identical CLI: windsurf <path> works per 2025 comparisons[1][2]). Validate all repo paths exist.",
        "testStrategy": "Create test registry.yaml with 2 repos. `pd list` outputs rich table with ID, path, priority. pytest tests/test_registry.py verifies parsing.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Setup SQLite Database Schema",
        "description": "Implement core/db.py with exact SQLModel schema for Repository and ContextSnapshot tables",
        "details": "Use SQLModel 0.0.22+: class Repository(SQLModel, table=True) with id:str=Field(primary_key=True), path:str, priority:int, active_branch:str, last_snapshot_id:Optional[int]=Field(default=None). class ContextSnapshot(SQLModel, table=True) with id:int=Field(primary_key=True, index=True), repo_id:str, timestamp:datetime, git_status_summary:str, terminal_last_command:str, terminal_output_summary:str, ai_sitrep:str. Use SQLite URL: f'sqlite+aiosqlite:///{config.db_path}' with aiosqlite 0.21+. Create engine with create_engine(..., connect_args={'check_same_thread': False}).",
        "testStrategy": "pytest tests/test_db.py: Create DB, insert Repository, insert ContextSnapshot, query back and verify data integrity and timestamps.",
        "priority": "high",
        "dependencies": [
          "1",
          "2"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement Git State Detection",
        "description": "Create git_utils to capture branch, dirty status, and diff summary for any repository",
        "details": "In core/git_utils.py: def get_status(repo_path: str) -> dict: Use subprocess.run(['git', 'rev-parse', '--abbrev-ref', 'HEAD']) for branch, ['git', 'status', '--porcelain'] for dirty files, ['git', 'diff', '--stat'] for summary. Return {'branch': str, 'is_dirty': bool, 'uncommitted_files': list[str], 'diff_stat': str}. Handle non-git repos gracefully.",
        "testStrategy": "pytest tests/test_git.py: Create temp git repo, make changes, verify get_status() returns correct dirty state and branch.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Implement Task Master Adapter",
        "description": "Create core/tasks.py to parse .taskmaster/tasks.json and extract active/in-progress tasks",
        "details": "def get_active_task(repo_path: str) -> Optional[dict]: Check for .taskmaster/tasks.json, load JSON, filter tasks where status=='in-progress', return highest priority or most recent. Schema matches user_json_schema exactly. Handle missing file gracefully (return None).",
        "testStrategy": "Create mock tasks.json with in-progress tasks, verify get_active_task() returns correct highest priority task.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Build AI Scribe Engine with Ollama Integration",
        "description": "Implement core/scribe.py for generating SITREP summaries using Ollama Qwen2.5-Coder",
        "details": "Use requests 2.32+ to POST to http://localhost:11434/api/generate. System prompt: 'You are a concise engineering assistant. Given git state, terminal logs, and active task, generate a 2-3 sentence SITREP with IMMEDIATE NEXT STEP in 50 words max.' Include active task from tasks.py, git_status_summary, terminal logs. Model: qwen2.5-coder (per spec). Timeout 5s. def generate_sitrep(repo_id: str, git_state: str, terminal_logs: str, active_task: Optional[dict]) -> str.",
        "testStrategy": "Manual: ollama serve, feed mock error traceback, verify coherent summary <50 words in <2s. Check prime.db ai_sitrep field.",
        "priority": "high",
        "dependencies": [
          "3",
          "4",
          "5"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Implement Terminal State Capture",
        "description": "Capture last 50 lines of active terminal and last command for freeze operation",
        "details": "In core/terminal.py: def capture_terminal_state() -> tuple[str, str]: Use subprocess.run(['tmux', 'capture-pane', '-p', '-S', '-50']) for last 50 lines, ['tmux', 'show-buffer'] or history parsing for last command. Fallback to 'history | tail -n 1' if not in tmux. Return (last_command: str, output_summary: str).",
        "testStrategy": "Manual: Run echo 'test error', pd freeze, verify terminal_output_summary contains 'test error' in DB.",
        "priority": "medium",
        "dependencies": [
          "3"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Implement Tmux Session Management",
        "description": "Create core/tmux.py for idempotent session create/attach with pd-<repo_id> naming",
        "details": "def ensure_session(repo_id: str, repo_path: str): session_name=f'pd-{repo_id}'. Check tmux ls | grep session_name, if exists: tmux attach -t session_name. Else: tmux new-session -d -s session_name 'cd {repo_path} && uv shell'. def detach_current(): tmux detach-client. Use subprocess.run(['tmux', ...], capture_output=True).",
        "testStrategy": "Manual Test 3.1: pd switch test-project (creates), detach, pd switch test-project (attaches existing, no duplication).",
        "priority": "high",
        "dependencies": [
          "2"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Windsurf Editor Control",
        "description": "Launch Windsurf editor with correct flags using configurable editor_cmd",
        "details": "In core/windsurf.py: def launch_editor(repo_path: str, editor_cmd: str): subprocess.Popen([editor_cmd, '-n', repo_path]) # -n = new window/instance (VSCode/Windsurf compatible per[1][3]). Windsurf confirmed as VSCode fork with identical CLI flags[1][2][6]. Reuse existing windows via Windsurf Hot Exit.",
        "testStrategy": "Manual Test 3.2: pd switch black-box opens Windsurf at correct path (new window or reuse existing).",
        "priority": "high",
        "dependencies": [
          "2"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Implement Core CLI Commands (list, status, doctor)",
        "description": "Build bin/pd CLI with Typer: pd list, pd status (rich table), pd doctor (health checks)",
        "details": "Typer app: @app.command() def list(): rich table of repos from registry. def status(): Enhanced table with git_state=git_utils.get_status(), last_snapshot from DB, emoji status (ðŸŸ¢ðŸ”´ðŸŸ¡). def doctor(): Check shutil.which('tmux'), which(editor_cmd), requests.get('http://localhost:11434/api/tags') contains 'qwen2.5-coder', all registry paths exist.",
        "testStrategy": "pd list shows registry table. pd doctor passes all checks when dependencies installed.",
        "priority": "high",
        "dependencies": [
          "2",
          "3",
          "4",
          "6"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Implement Freeze Operation (Snapshot Current State)",
        "description": "Create pd freeze: capture git/terminal/task state, generate AI SITREP, save to DB",
        "details": "In bin/pd: @app.command() def freeze(repo_id: str): current_path=get_cwd_repo(), git_state=git_utils.get_status(), terminal=terminal.capture(), task=tasks.get_active_task(), sitrep=scribe.generate_sitrep(...), db.save_snapshot(repo_id, git_state..., sitrep). Timestamp=datetime.utcnow().",
        "testStrategy": "Manual Test 2.3: In dirty repo run pd freeze, verify new DB row with AI summary.",
        "priority": "high",
        "dependencies": [
          "3",
          "4",
          "5",
          "6",
          "7"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Implement Switch/Warp Protocol (Full Context Switch)",
        "description": "Core pd switch <repo>: freeze current -> thaw target with SITREP display",
        "details": "def switch(repo_id: str): if current_repo(): freeze(current_repo()). target=tmux.ensure_session(repo_id, path), windsurf.launch_editor(path, editor_cmd). Print rich SITREP banner: last_snapshot=DB.get_latest(repo_id), f'>>> LAST ACTION: {snapshot.ai_sitrep}\\n>>> GIT: {git_status}\\n>>> NEXT: {next_step}'.",
        "testStrategy": "Full E2E: pd switch repo1 (freeze), pd switch repo2 (thaw+display SITREP), verify tmux attaches correctly.",
        "priority": "high",
        "dependencies": [
          "8",
          "9",
          "10",
          "11"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Implement Shell Integration (zsh wrapper)",
        "description": "Create system/shell_integration.zsh with cd/tmux hijacking for seamless pd switch",
        "details": "In ~/.zshrc: source path/to/shell_integration.zsh. function cd() { if [[ $1 == pd-* ]]; then pd switch ${1#pd-}; else builtin cd $@; fi }. Alias pd=~/path/to/bin/pd. Auto-attach tmux on pd switch.",
        "testStrategy": "Manual Test 3.3: Source integration, type 'cd pd-rna-predict', verify enters tmux session.",
        "priority": "medium",
        "dependencies": [
          "12"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement Background Daemon Service",
        "description": "Create bin/pd-daemon for Watchdog monitoring and auto-freeze on inactivity",
        "details": "Use watchdog 5.0+: monitor registry repo paths, on file changes or inactivity (>30min) trigger freeze(). Run as `pd-daemon` service with systemd or nohup. Log to data/logs/.",
        "testStrategy": "Run pd-daemon, modify file in watched repo, verify auto-freeze creates DB snapshot.",
        "priority": "low",
        "dependencies": [
          "11"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Comprehensive Integration Testing and Amnesia Test",
        "description": "Run full verification suite including Amnesia Test and Crash Test",
        "details": "Execute all manual tests 1.1-3.3. Amnesia Test: Work on repo1 30min, switch away 24h, pd switch repo1, commit code <5min. Crash Test: kill terminal, pd switch, verify exact state restored.",
        "testStrategy": "Pass all 6 Green Lights + Amnesia/Crash tests. Tune scribe prompt if SITREP insufficient.",
        "priority": "high",
        "dependencies": [
          "13"
        ],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "Prepare Environment for Integration Testing",
            "description": "Set up the testing environment to ensure all dependencies and configurations are ready for the integration tests.",
            "dependencies": [],
            "details": "Ensure that all necessary services are running and accessible. Verify that the latest code is checked out and all dependencies are installed. Confirm that the testing environment mirrors the production environment as closely as possible.",
            "status": "done",
            "testStrategy": "Verify that all services are running and accessible by executing a simple connectivity test.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Execute Manual Tests 1.1-3.3",
            "description": "Run the specified manual tests to verify basic functionality before proceeding with Amnesia and Crash tests.",
            "dependencies": [
              1
            ],
            "details": "Follow the manual test scripts for tests 1.1 through 3.3. Document any deviations or unexpected results. Ensure that each test passes as expected before moving on.\n<info added on 2025-12-15T23:34:08.323Z>\nManual test results (stand-in repo = prime-directive):\n- Test 2.3 freeze hook: ran freeze with marker note and verified latest snapshot in DB contains marker in human_note and terminal_output_summary.\n- Test 3.1 tmux idempotency: ensure_session called twice; tmux list-sessions shows only pd-prime-directive; no suffix sessions.\n- Test 3.2/3.3 interactive: user confirmed editor launch + shell/tmux integration working.\nNote: configured db_path (~/.prime-directive/data/prime.db) directory was missing; snapshot written to repo-local data/prime.db during testing.\n</info added on 2025-12-15T23:34:08.323Z>",
            "status": "done",
            "testStrategy": "Record the results of each test and compare them against expected outcomes documented in the test scripts.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Conduct Amnesia Test",
            "description": "Perform the Amnesia Test to verify system behavior after a period of inactivity.",
            "dependencies": [
              2
            ],
            "details": "Work on repo1 for 30 minutes, then switch away for 24 hours. After 24 hours, switch back to repo1 and commit code within 5 minutes. Document the state of the system before and after the inactivity period.",
            "status": "deferred",
            "testStrategy": "Ensure that the system state is consistent with expectations after the 24-hour period and that the commit is successful without errors.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Conduct Crash Test",
            "description": "Perform the Crash Test to verify system recovery after an unexpected shutdown.",
            "dependencies": [
              3
            ],
            "details": "Simulate a crash by killing the terminal session. Use 'pd switch' to restore the session and verify that the exact state is restored. Document the steps taken and the state of the system before and after the crash.",
            "status": "pending",
            "testStrategy": "Check that all data and session states are restored accurately and that no data is lost or corrupted.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Document Test Results and Observations",
            "description": "Compile a detailed report of the test results, including any issues encountered and their resolutions.",
            "dependencies": [
              4
            ],
            "details": "Create a comprehensive document that includes the results of all tests conducted, any anomalies observed, and steps taken to resolve issues. Include screenshots or logs as necessary to support findings.",
            "status": "pending",
            "testStrategy": "Review the document for completeness and accuracy. Ensure that all findings are clearly explained and supported by evidence.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Review and Finalize Test Documentation",
            "description": "Conduct a peer review of the test documentation to ensure accuracy and completeness.",
            "dependencies": [
              5
            ],
            "details": "Have a team member review the test documentation for clarity, accuracy, and completeness. Address any feedback or corrections needed.",
            "status": "pending",
            "testStrategy": "Ensure that the final document is approved by the reviewer and is ready for submission or archiving.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 16,
        "title": "P0: Fix tmux attach blocking + remove shell injection risk",
        "description": "Prevent pd switch workflow from hanging and eliminate shell-injection risk in tmux session creation.",
        "details": "Audit-derived fixes in core/tmux.py: (1) Avoid blocking the Python process mid-switch via tmux attach-session; prefer exec-style attach (os.execvp) or ensure attach only happens at the very end if intended. (2) Remove shell injection risk from bash -c string interpolation; prefer tmux new-session -c <repo_path> and start shell without concatenated commands, or escape paths safely. Ensure behavior is correct both inside tmux (switch-client) and outside tmux (attach/exec).",
        "testStrategy": "Add/extend tests to validate safe command construction and that switch can proceed to editor launch/SITREP display in non-tmux environments. Manual test: Monday morning warp scenario does not hang.",
        "priority": "high",
        "dependencies": [
          "8",
          "12"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Audit tmux session creation for blocking issues",
            "description": "Identify and document areas in core/tmux.py where tmux attach-session might block the Python process.",
            "dependencies": [],
            "details": "Review the current implementation of tmux session creation and identify where the process might hang due to blocking calls. Document these areas for further action.",
            "status": "done",
            "testStrategy": "Run the current workflow and log any instances where the process hangs to verify the identified blocking points.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement exec-style attach for tmux sessions",
            "description": "Replace blocking tmux attach-session calls with os.execvp to prevent the Python process from hanging.",
            "dependencies": [
              1
            ],
            "details": "Modify the code to use os.execvp for attaching to tmux sessions, ensuring that the attach happens only at the end of the workflow if intended.",
            "status": "done",
            "testStrategy": "Test the workflow to ensure that the process does not hang and that the session attaches correctly at the intended point.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Remove shell injection risk in tmux session creation",
            "description": "Eliminate shell injection risks by using tmux new-session -c <repo_path> and avoiding command concatenation.",
            "dependencies": [],
            "details": "Refactor the code to use tmux's -c option for setting the working directory and ensure that no shell command concatenation is used. Use shlex.quote for any necessary path handling.",
            "status": "done",
            "testStrategy": "Conduct security tests to ensure that no shell injection vulnerabilities exist in the session creation process.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Ensure correct behavior inside tmux using switch-client",
            "description": "Verify and adjust the behavior of the workflow when executed inside an existing tmux session using switch-client.",
            "dependencies": [
              2,
              3
            ],
            "details": "Test and modify the workflow to ensure that it correctly uses tmux switch-client when inside a tmux session, without causing any blocking or security issues.",
            "status": "done",
            "testStrategy": "Run the workflow inside a tmux session and confirm that it switches clients correctly without hanging or security risks.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Ensure correct behavior outside tmux using attach/exec",
            "description": "Verify and adjust the behavior of the workflow when executed outside of a tmux session using attach/exec.",
            "dependencies": [
              2,
              3
            ],
            "details": "Ensure that the workflow correctly attaches or executes a new tmux session when run outside of tmux, without blocking or security issues.",
            "status": "done",
            "testStrategy": "Run the workflow outside of a tmux session and confirm that it attaches or executes correctly without hanging or security risks.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Develop unit tests and mocks for tmux session management",
            "description": "Create unit tests and mocks to verify the correct behavior of tmux session management in various scenarios.",
            "dependencies": [
              4,
              5
            ],
            "details": "Develop comprehensive unit tests that cover both inside and outside tmux scenarios, ensuring that all code paths are tested for blocking and security issues.",
            "status": "done",
            "testStrategy": "Run the unit tests to ensure all scenarios are covered and that the code behaves as expected in each case.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 17,
        "title": "P0: Make Ollama SITREP generation resilient (retry/backoff + configurable timeout)",
        "description": "Improve scribe robustness so freeze/switch degrade gracefully when Ollama is down or slow.",
        "details": "Implement in core/scribe.py: configurable timeout via Hydra (e.g., system.ollama_timeout_seconds). Add retry with exponential backoff for transient errors. Change error strategy so callers can distinguish failure from a real SITREP (typed exception or structured result), and in pd.py ensure snapshots still save with fallback SITREP if Ollama fails.",
        "testStrategy": "Add tests that simulate timeouts/connection errors and assert freeze still succeeds with a fallback SITREP and does not crash.",
        "priority": "high",
        "dependencies": [
          "6",
          "11"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Configurable Timeout",
            "description": "Add a configurable timeout setting for Ollama SITREP generation using Hydra.",
            "dependencies": [],
            "details": "Modify core/scribe.py to include a new configuration parameter 'system.ollama_timeout_seconds' using Hydra. Ensure this parameter can be easily adjusted via configuration files.",
            "status": "done",
            "testStrategy": "Create unit tests to verify that the timeout configuration is correctly read and applied in the SITREP generation process.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Retry with Exponential Backoff",
            "description": "Add retry logic with exponential backoff for transient errors during SITREP generation.",
            "dependencies": [
              1
            ],
            "details": "Use the Tenacity library to implement retry logic in core/scribe.py. Configure it to handle specific transient errors and apply exponential backoff strategy.",
            "status": "done",
            "testStrategy": "Write unit tests to simulate transient errors and verify that retries occur with the correct backoff intervals.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Define Error Handling Strategy",
            "description": "Establish a clear error handling strategy to distinguish between SITREP failures and successful responses.",
            "dependencies": [
              2
            ],
            "details": "Introduce a new typed exception or structured result in core/scribe.py to differentiate between errors and valid SITREP responses. Update callers to handle these appropriately.",
            "status": "done",
            "testStrategy": "Develop tests to ensure that errors are correctly classified and handled by the calling functions.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrate Fallback SITREP Mechanism",
            "description": "Ensure that snapshots still save with a fallback SITREP if Ollama fails.",
            "dependencies": [
              3
            ],
            "details": "Modify pd.py to implement a fallback mechanism that triggers when SITREP generation fails, ensuring snapshots are saved with a default or cached SITREP.",
            "status": "done",
            "testStrategy": "Test the fallback mechanism by simulating SITREP generation failures and verifying that snapshots are saved correctly.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "CLI Integration for Freeze and Switch",
            "description": "Update CLI commands for freeze and switch to handle new SITREP generation logic.",
            "dependencies": [
              4
            ],
            "details": "Modify CLI command implementations to incorporate the new timeout, retry, and error handling logic. Ensure user feedback is clear and informative.",
            "status": "done",
            "testStrategy": "Perform integration tests to ensure CLI commands behave correctly under various SITREP generation scenarios.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Develop Unit Tests for SITREP Generation",
            "description": "Create comprehensive unit tests for the SITREP generation process, covering all new features.",
            "dependencies": [
              5
            ],
            "details": "Develop unit tests in the test suite to cover configurable timeout, retry logic, error handling, and fallback mechanisms.",
            "status": "done",
            "testStrategy": "Ensure all new and existing tests pass, and edge cases are covered.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Conduct Chaos Testing",
            "description": "Perform chaos testing to validate the resilience of the SITREP generation process under failure conditions.",
            "dependencies": [
              6
            ],
            "details": "Introduce controlled failures and delays in the SITREP generation process to test the robustness of the implemented features.",
            "status": "done",
            "testStrategy": "Use chaos engineering tools to simulate failures and verify that the system degrades gracefully and recovers as expected.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 18,
        "title": "P1: DB integrity + performance improvements (FKs, indexes, relationships)",
        "description": "Add schema constraints and query optimizations to prevent orphaned snapshots and improve latest-snapshot queries.",
        "details": "Update core/db.py: add FK constraint from ContextSnapshot.repo_id -> Repository.id and define relationships if helpful. Add index to optimize (repo_id, timestamp) latest-snapshot retrieval. Ensure engine lifecycle is safe if multiple db_path values are used (dispose old engine or key engines by path).",
        "testStrategy": "Extend tests/test_db.py to cover FK behavior (no orphan snapshots) and validate latest-snapshot query correctness.",
        "priority": "medium",
        "dependencies": [
          "3"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add Foreign Key Constraint",
            "description": "Implement a foreign key constraint from ContextSnapshot.repo_id to Repository.id to ensure referential integrity.",
            "dependencies": [],
            "details": "Modify the core/db.py to include a foreign key constraint in the SQLModel definition for ContextSnapshot. Ensure that the foreign key is correctly defined to prevent orphaned snapshots.",
            "status": "done",
            "testStrategy": "Create test cases to insert a ContextSnapshot with a valid and invalid repo_id, ensuring that the invalid insertions are rejected.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Define Relationships in SQLModel",
            "description": "Define relationships in SQLModel to facilitate ORM operations between ContextSnapshot and Repository.",
            "dependencies": [
              1
            ],
            "details": "Update the SQLModel definitions to include relationship attributes. This will allow for easier navigation and querying between related tables.",
            "status": "done",
            "testStrategy": "Write tests to verify that relationship attributes allow for correct data retrieval and manipulation between ContextSnapshot and Repository.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add Index for Latest Snapshot Query",
            "description": "Create an index on the (repo_id, timestamp) columns to optimize queries for retrieving the latest snapshot.",
            "dependencies": [
              1
            ],
            "details": "Modify the database schema to include an index on the (repo_id, timestamp) columns. This will improve the performance of queries that retrieve the latest snapshot for a given repository.",
            "status": "done",
            "testStrategy": "Benchmark query performance before and after index creation to ensure a noticeable improvement in retrieval times.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Engine Lifecycle Management",
            "description": "Ensure that the database engine lifecycle is managed safely when multiple db_path values are used.",
            "dependencies": [],
            "details": "Update the database connection logic to dispose of old engines or manage engines keyed by db_path. This will prevent resource leaks and ensure that each db_path uses a distinct engine.",
            "status": "done",
            "testStrategy": "Simulate scenarios with multiple db_path values and verify that engines are correctly disposed of or reused as appropriate.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Plan Migration and Backward Compatibility",
            "description": "Develop a migration plan to apply schema changes without disrupting existing data or applications.",
            "dependencies": [
              1,
              3
            ],
            "details": "Create migration scripts using a tool like Alembic to apply the new constraints and indexes. Ensure that the migration can be applied to existing databases without data loss.",
            "status": "done",
            "testStrategy": "Test the migration process on a copy of the production database to ensure that it applies cleanly and maintains data integrity.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Update Tests for Schema Changes",
            "description": "Revise existing tests and add new tests to cover the updated schema constraints and performance improvements.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Review and update the test suite to ensure that all new constraints, relationships, and indexes are adequately tested. Add new tests where necessary.",
            "status": "done",
            "testStrategy": "Run the full test suite to ensure all tests pass and that new tests cover the intended functionality.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Document Schema and Performance Improvements",
            "description": "Update the project documentation to reflect the new schema constraints, relationships, and performance optimizations.",
            "dependencies": [
              1,
              2,
              3,
              5
            ],
            "details": "Revise the database schema documentation to include details of the new foreign key constraints, relationships, and indexes. Document the rationale and expected performance improvements.",
            "status": "done",
            "testStrategy": "Review the documentation for accuracy and completeness. Ensure that it is understandable to new developers and stakeholders.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 19,
        "title": "P1: Introduce Orchestrator for atomic switch semantics + nested repo detection",
        "description": "Centralize freeze/switch/thaw into an orchestration layer with clearer failure semantics.",
        "details": "Create core/orchestrator.py (or similar) that coordinates freeze -> session/editor -> sitrep display with consistent error handling. Improve current repo detection to handle nested repo paths by selecting the longest matching repo path. Add transaction-like semantics: if session/editor operations fail, avoid leaving user in a half-switched state; ensure DB engine cleanup is consistent.",
        "testStrategy": "Add unit tests for nested repo detection (longest-prefix match) and failure paths (ensure_session failure does not crash and resources are cleaned up).",
        "priority": "medium",
        "dependencies": [
          "11",
          "12"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Orchestrator API",
            "description": "Create a clear API for the orchestrator that will manage freeze, switch, and thaw operations with consistent error handling.",
            "dependencies": [],
            "details": "Define the methods and interfaces for the orchestrator in a new file, core/orchestrator.py. Ensure the API supports transaction-like semantics to handle failures gracefully.",
            "status": "done",
            "testStrategy": "Review the API design with the team and create mock implementations to validate the interface.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Orchestrator Core Logic",
            "description": "Develop the core logic for the orchestrator to manage the sequence of operations: freeze, session/editor, and sitrep display.",
            "dependencies": [
              1
            ],
            "details": "Implement the orchestrator methods defined in the API. Ensure each step is atomic and includes error handling to rollback changes if necessary.",
            "status": "done",
            "testStrategy": "Write unit tests for each orchestrator method to ensure they handle errors and rollback correctly.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Refactor Existing Logic into Orchestrator",
            "description": "Move existing logic from pd.py into the orchestrator to centralize control flow and error handling.",
            "dependencies": [
              2
            ],
            "details": "Identify and extract relevant logic from pd.py and integrate it into the orchestrator. Ensure that the orchestrator is the single point of control for these operations.",
            "status": "done",
            "testStrategy": "Run existing tests to ensure functionality remains unchanged after refactoring.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Enhance Nested Repo Detection",
            "description": "Improve repository detection to handle nested repo paths by selecting the longest matching repo path.",
            "dependencies": [
              3
            ],
            "details": "Modify the repo detection logic to iterate through potential repo paths and select the longest valid path. Update the orchestrator to use this enhanced detection.",
            "status": "done",
            "testStrategy": "Create test cases with nested repo structures to verify the correct path is selected.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Failure Semantics and Rollback",
            "description": "Ensure that the orchestrator implements transaction-like semantics to avoid leaving users in a half-switched state.",
            "dependencies": [
              2
            ],
            "details": "Develop rollback mechanisms within the orchestrator to revert changes if any step in the process fails. Ensure consistent DB engine cleanup.",
            "status": "done",
            "testStrategy": "Simulate failures at each step and verify that the system rolls back to a consistent state.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Order Tmux/Editor Operations",
            "description": "Ensure that tmux and editor operations are ordered correctly within the orchestrator.",
            "dependencies": [
              2
            ],
            "details": "Review the sequence of operations involving tmux and editors to ensure they are executed in the correct order. Adjust the orchestrator logic as needed.",
            "status": "done",
            "testStrategy": "Test with various tmux and editor configurations to ensure operations are ordered and executed correctly.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Develop Unit and Integration Tests",
            "description": "Create comprehensive unit and integration tests for the orchestrator to ensure all functionalities work as expected.",
            "dependencies": [
              3,
              4,
              5,
              6
            ],
            "details": "Develop tests that cover all orchestrator functionalities, including error handling, rollback, and nested repo detection.",
            "status": "done",
            "testStrategy": "Execute the full suite of tests and validate that all pass, ensuring the orchestrator behaves correctly in all scenarios.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 20,
        "title": "P1: Unify configuration system (Hydra vs registry.yaml) to remove duplication",
        "description": "Resolve architectural duplication from multiple configuration sources and ensure daemon/CLI use the same config pipeline.",
        "details": "Audit calls out multiple config systems (Hydra structured config, registry YAML parsing). Decide on a single source of truth and refactor remaining modules (including daemon) to load config consistently. Remove redundant config code/files only if safe and update docs/tests accordingly.",
        "testStrategy": "Tests should confirm CLI and daemon load identical repo/system settings (mock_mode, db_path, editor_cmd) from the single config source.",
        "priority": "medium",
        "dependencies": [
          "2",
          "14"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Inventory Current Configuration Sources",
            "description": "Identify and document all current configuration sources, including Hydra and registry.yaml, used across the system.",
            "dependencies": [],
            "details": "Conduct a thorough audit of the codebase to list all configuration files and systems in use. Document their usage, scope, and any interdependencies.",
            "status": "done",
            "testStrategy": "Review the documentation to ensure all configuration sources are accounted for and correctly described.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Decide on a Single Source of Truth",
            "description": "Determine which configuration system will be the single source of truth for the application.",
            "dependencies": [
              1
            ],
            "details": "Evaluate the pros and cons of Hydra and registry.yaml. Consider factors such as flexibility, ease of use, and integration with existing systems. Make a decision and document the rationale.",
            "status": "done",
            "testStrategy": "Validate the decision with stakeholders and ensure it aligns with project goals.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Refactor pd.py to Use the Unified Configuration System",
            "description": "Refactor the pd.py module to load configuration from the chosen source of truth.",
            "dependencies": [
              2
            ],
            "details": "Update pd.py to remove any direct references to deprecated configuration systems. Implement loading and parsing logic using the unified configuration system.",
            "status": "done",
            "testStrategy": "Write unit tests to verify that pd.py correctly loads and applies configuration settings.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Refactor pd_daemon.py to Use the Unified Configuration System",
            "description": "Refactor the pd_daemon.py module to load configuration from the chosen source of truth.",
            "dependencies": [
              2
            ],
            "details": "Update pd_daemon.py to ensure it uses the unified configuration system. Remove any legacy configuration code.",
            "status": "done",
            "testStrategy": "Conduct integration tests to ensure pd_daemon.py operates correctly with the new configuration system.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Refactor Core and Registry Usage",
            "description": "Update core and registry modules to utilize the unified configuration system.",
            "dependencies": [
              2
            ],
            "details": "Identify all instances where core and registry modules interact with configuration systems. Refactor these to use the unified configuration system.",
            "status": "done",
            "testStrategy": "Perform regression tests on core and registry functionalities to ensure no disruptions occur.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Deprecate and Remove Redundant Configuration Code",
            "description": "Safely deprecate and remove any redundant configuration code and files.",
            "dependencies": [
              3,
              4,
              5
            ],
            "details": "Identify redundant configuration files and code. Ensure they are no longer in use before removing them. Update any references in the codebase.",
            "status": "done",
            "testStrategy": "Run a full suite of tests to confirm that removing the redundant code does not affect system functionality.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Update Documentation and Add Tests",
            "description": "Update all relevant documentation to reflect the new configuration system and add tests to verify consistent application of configurations.",
            "dependencies": [
              6
            ],
            "details": "Revise user and developer documentation to describe the new configuration system. Add comprehensive tests to ensure configurations are applied consistently across all modules.",
            "status": "done",
            "testStrategy": "Review documentation for accuracy and completeness. Ensure new tests cover all configuration scenarios.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 21,
        "title": "P2: Add integration/chaos tests for end-to-end workflow (Monday Morning Warp)",
        "description": "Add higher-level tests to validate freeze/switch/thaw end-to-end and resilience under dependency failures.",
        "details": "Add integration tests for pd freeze + pd switch in mock mode; chaos test when Ollama is down to confirm graceful degradation; extend git parsing tests to cover renames/copies/conflicts; optional property-based tests for parsing robustness.",
        "testStrategy": "CI-safe execution: tests should run without requiring tmux or Ollama (use mocks/mock_mode).",
        "priority": "low",
        "dependencies": [
          "16",
          "17",
          "19"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up Integration Test Harness in Mock Mode",
            "description": "Create an integration test harness that operates in mock mode to simulate the end-to-end workflow without external dependencies.",
            "dependencies": [],
            "details": "Develop a test harness that can simulate the entire workflow in a controlled environment. Ensure it can mock external services and dependencies to allow for isolated testing.",
            "status": "done",
            "testStrategy": "Verify the harness can run basic workflow simulations without real external service calls.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Freeze and Switch End-to-End Tests",
            "description": "Develop integration tests to validate the freeze and switch operations in the end-to-end workflow using the mock mode harness.",
            "dependencies": [
              1
            ],
            "details": "Write tests that execute the freeze and switch operations, ensuring that the system behaves as expected through the entire workflow.",
            "status": "done",
            "testStrategy": "Run the tests in the mock mode harness and verify that the operations complete successfully without errors.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop Chaos Test for Ollama Down Scenario",
            "description": "Create a chaos test to simulate the scenario where Ollama is down, ensuring the system degrades gracefully.",
            "dependencies": [
              1
            ],
            "details": "Introduce a failure in the mock mode to simulate Ollama being down and observe how the system handles the failure.",
            "status": "done",
            "testStrategy": "Check that the system continues to operate with reduced functionality and logs appropriate error messages.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Extend Git Parsing Tests for Renames, Copies, and Conflicts",
            "description": "Enhance existing git parsing tests to cover scenarios involving file renames, copies, and merge conflicts.",
            "dependencies": [],
            "details": "Add test cases to the git parsing suite that specifically address the handling of renames, copies, and conflicts in git repositories.",
            "status": "done",
            "testStrategy": "Run the extended test suite and ensure all new scenarios are correctly parsed and handled.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Optional Property-Based Tests for Parsing Robustness",
            "description": "Introduce property-based tests to ensure robustness in parsing logic, focusing on edge cases and unexpected inputs.",
            "dependencies": [
              4
            ],
            "details": "Use a property-based testing framework like Hypothesis to generate a wide range of inputs and validate the parsing logic against them.",
            "status": "done",
            "testStrategy": "Verify that the parsing logic handles all generated inputs without errors or unexpected behavior.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Document Integration and Chaos Testing Strategies",
            "description": "Create comprehensive documentation for the integration and chaos testing strategies implemented.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Write detailed documentation explaining the purpose, setup, and execution of the integration and chaos tests, including any mock configurations.",
            "status": "done",
            "testStrategy": "Review the documentation for completeness and clarity, ensuring it can be followed by other developers.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Integrate Tests into Continuous Integration Pipeline",
            "description": "Ensure all new tests are integrated into the CI pipeline to run automatically on code changes.",
            "dependencies": [
              2,
              3,
              4,
              5
            ],
            "details": "Modify the CI configuration to include the new integration, chaos, and parsing tests, ensuring they run in a CI-safe environment.",
            "status": "done",
            "testStrategy": "Trigger the CI pipeline and verify that all tests execute successfully and report results as expected.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 22,
        "title": "Tier 1: Smart dependency detection + actionable guidance (no auto-install of system deps)",
        "description": "Add dependency detection utilities and enhance pd doctor to provide copy-paste install/start/pull guidance for Ollama and optional OpenAI fallback.",
        "details": "Implement core/dependencies.py with platform-aware install guidance (macOS/Linux/other) and checks for: Ollama installed, Ollama API running, model pulled (qwen2.5-coder), and OpenAI API key present. Enhance pd doctor output to clearly show install/start commands and model pull commands. Explicitly do NOT auto-install system binaries; only provide guidance.",
        "testStrategy": "Unit tests for platform detection and doctor output behavior using mocks (shutil.which, requests.get). Manual: pd doctor prints actionable steps when Ollama is missing/not running/model missing.",
        "priority": "high",
        "dependencies": [
          "10"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 23,
        "title": "Tier 2: AI provider manager with OpenAI fallback + cost/consent guardrails",
        "description": "Introduce AI provider abstraction (Ollama primary, OpenAI fallback) with explicit user consent and budget controls.",
        "details": "Create core/ai_providers.py defining provider interfaces for Ollama and OpenAI. Add Hydra config fields for primary/fallback providers/models, monthly budget, and require-confirmation flag. Implement selection logic: try Ollama first; if unavailable, fall back to OpenAI only if configured and within budget/consent settings. Ensure provider choice is clearly logged.\n<info added on 2025-12-15T04:00:37.349Z>\nFixed all 41 nitpick and 20 actionable comments from PR_ISSUES_DEC14_2025.md CodeRabbit review. Key fixes include narrowing blind Exception catches, fixing unused variables, adding f-string conversion flags, addressing datetime.utcnow deprecation, adding task validation in tasks.py, resolving Hydra config path issue, incorporating python-dotenv for .env loading, and switching from Ollama to OpenAI as the primary provider. All 53 tests pass.\n</info added on 2025-12-15T04:00:37.349Z>",
        "testStrategy": "Unit tests simulating: Ollama up, Ollama down with OpenAI key set, Ollama down without OpenAI key, and budget/consent blocking fallback. Verify freeze still produces a SITREP or a clear placeholder without crashing.",
        "priority": "high",
        "dependencies": [
          "6",
          "22"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 24,
        "title": "Tier 2: Usage tracking + budget enforcement for paid AI fallback",
        "description": "Track OpenAI fallback usage in SQLite and enforce monthly budget limits to prevent bill shock.",
        "details": "Implement a lightweight usage tracker (SQLite table in existing db or separate file) to record provider, timestamp, rough token counts/cost estimates, and outcome. Add budget checks used by the provider manager. Add a CLI command (e.g., pd ai-usage) or enhance doctor/status to show month-to-date cost.",
        "testStrategy": "Unit tests for cost aggregation and budget blocking logic. Integration test: simulate multiple OpenAI fallbacks and verify budget enforcement stops further calls and returns a clear message.",
        "priority": "medium",
        "dependencies": [
          "3",
          "23"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design SQLite Schema for Usage Tracking",
            "description": "Create a schema for an SQLite table to track AI fallback usage, including fields for provider, timestamp, token counts, cost estimates, and outcome.",
            "dependencies": [],
            "details": "Design a table with columns: id (primary key), provider (text), timestamp (datetime), token_count (integer), cost_estimate (real), and outcome (text). Ensure the table can efficiently handle queries for monthly aggregation.",
            "status": "done",
            "testStrategy": "Verify the table creation with a migration script and check that all fields are correctly set up.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Logging of Usage Data",
            "description": "Add functionality to log each usage event to the SQLite table whenever an AI fallback is used.",
            "dependencies": [
              1
            ],
            "details": "Modify the provider manager to insert a new record into the SQLite table each time an AI fallback is triggered. Ensure all relevant data is captured accurately.",
            "status": "done",
            "testStrategy": "Simulate AI fallback usage and verify that records are correctly inserted into the database.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop Monthly Usage Aggregation Logic",
            "description": "Create a function to aggregate usage data on a monthly basis, calculating total token counts and cost estimates.",
            "dependencies": [
              2
            ],
            "details": "Implement a query that sums token counts and cost estimates for the current month, grouped by provider. Ensure the function can be called to retrieve these aggregates efficiently.",
            "status": "done",
            "testStrategy": "Test the aggregation function with sample data to ensure it returns correct monthly totals.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Budget Enforcement Mechanism",
            "description": "Add logic to enforce monthly budget limits based on aggregated usage data, preventing further usage if limits are exceeded.",
            "dependencies": [
              3
            ],
            "details": "Define budget limits and implement checks in the provider manager to compare current usage against these limits. Trigger alerts or block further usage if limits are exceeded.",
            "status": "done",
            "testStrategy": "Set a budget limit and simulate usage to test that the system correctly enforces the limit and prevents overuse.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add CLI Command for Usage Reporting",
            "description": "Create a CLI command to display month-to-date usage and cost information, allowing users to monitor their usage against budget limits.",
            "dependencies": [
              3
            ],
            "details": "Develop a command (e.g., 'pd ai-usage') that retrieves and displays aggregated usage data for the current month. Include details such as total tokens used and cost estimates.",
            "status": "done",
            "testStrategy": "Run the CLI command and verify that it outputs accurate and complete usage data.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Develop Comprehensive Test Suite",
            "description": "Create a set of tests to cover all aspects of the usage tracking and budget enforcement features, ensuring robustness and reliability.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Write unit and integration tests for each component: schema setup, logging, aggregation, budget checks, and CLI reporting. Use mock data to simulate various scenarios.",
            "status": "done",
            "testStrategy": "Execute the test suite to confirm that all components function correctly and handle edge cases as expected.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 25,
        "title": "Tier 3 (Optional): Auto-install Python-only dependencies (allowlist, venv-only)",
        "description": "Optionally auto-install missing Python packages (e.g., openai, tenacity) inside the active venv using a strict allowlist; never install system binaries.",
        "details": "Implement core/auto_installer.py that checks for allowlisted packages and installs them with pip inside the current interpreter environment. Add Hydra config flag auto_install_python_deps and keep auto_install_system_deps forced false. Integrate into OpenAI provider initialization if enabled.",
        "testStrategy": "Unit tests that mock subprocess/pip calls and verify allowlist enforcement. Ensure feature is off by default and does not run in CI unless explicitly enabled.",
        "priority": "low",
        "dependencies": [
          "23"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 26,
        "title": "Fix Shell Integration and Process Hierarchy",
        "description": "Resolve the fragile process hierarchy issue caused by the pd switch command, ensuring tmux sessions are not orphaned if Python exits unexpectedly.",
        "details": "The current implementation of the pd switch command results in a fragile process hierarchy where Python remains the parent of the tmux client. This can lead to orphaned tmux sessions if Python exits unexpectedly. To address this, modify pd.py to exit with a specific status code or write a token file upon successful execution. Update shell_integration.zsh to trap this status code or token file, and execute tmux switch-client at the shell level, effectively removing Python from the process chain. This change will ensure that tmux sessions are managed independently of the Python process, improving the robustness of the session management.\n<info added on 2025-12-15T23:45:15.476Z>\nImplemented shell-level tmux attach/switch to fix process hierarchy:\n- core/orchestrator.run_switch now returns a boolean (needs_shell_attach) instead of attaching to tmux.\n- bin/pd.py exits with code 88 on 'pd switch' when shell attach is required.\n- system/shell_integration.zsh traps exit code 88 and performs tmux attach-session / switch-client in the shell.\n- Updated tests/test_switch.py to cover both normal switch (exit 0) and shell-attach handshake (exit 88). pytest tests/test_switch.py passes.\n</info added on 2025-12-15T23:45:15.476Z>",
        "testStrategy": "1. Modify pd.py to exit with a specific status code or write a token file upon successful execution.\\n2. Update shell_integration.zsh to trap the status code or check for the token file.\\n3. Execute tmux switch-client at the shell level based on the trapped status or token file.\\n4. Test by running pd switch and forcibly terminating the Python process to ensure the tmux session remains active and is not orphaned.\\n5. Verify that the shell integration correctly handles the status code or token file and executes the tmux switch-client command.",
        "status": "done",
        "dependencies": [
          "13",
          "16"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 27,
        "title": "Clean Up Technical Debt: Code Removal, WAL Mode, Refactoring, and Alembic Setup",
        "description": "Refactor windsurf.py to accept configurable editor_args from Hydra config instead of using the hardcoded -n flag. This change will improve compatibility with editors other than VSCode, such as vim.",
        "status": "done",
        "dependencies": [
          "20"
        ],
        "priority": "medium",
        "details": "1. **Refactor windsurf.py**: Update `windsurf.py` to accept configurable `editor_args` from the Hydra configuration instead of using the hardcoded `-n` flag. This will improve compatibility with editors that do not support the `-n` flag, such as vim. \n\n2. **Update Configuration**: Add an `editor_args` field to `config.yaml` to allow users to specify their preferred editor arguments. Ensure that the application reads this configuration correctly and applies it when launching the editor.\n<info added on 2025-12-16T00:10:23.148Z>\nImplemented configurable editor args:\n- Added `system.editor_args` (list[str]) to Hydra schema (SystemConfig) with default `['-n']`.\n- Added `system.editor_args` to `conf/config.yaml`.\n- Refactored `core/windsurf.launch_editor` to accept `editor_args` and build command accordingly (no more hardcoded `-n`).\n- Wired orchestrator switch flow to pass `cfg.system.editor_args` into `launch_editor`.\n- Updated `tests/test_windsurf.py` for custom args; full suite passes.\nVerification: `pytest -q` (61 passed).\n</info added on 2025-12-16T00:10:23.148Z>",
        "testStrategy": "1. **Refactor windsurf.py**: Test the `windsurf.py` functionality with different editors by specifying various `editor_args` in the Hydra configuration. Ensure that the application launches the editor correctly without the `-n` flag.\n\n2. **Configuration Verification**: Verify that the `editor_args` field in `config.yaml` is correctly parsed and applied by the application. Test with multiple configurations to ensure flexibility and correctness.",
        "subtasks": []
      },
      {
        "id": 28,
        "title": "Fix Async I/O Architecture",
        "description": "Replace blocking I/O calls with asynchronous alternatives to improve performance and prevent freezes.",
        "details": "1. Replace `requests.post` in `ai_providers.py` with `httpx.AsyncClient.post` to make HTTP requests asynchronously. Ensure that the function calling it is also async and handle the response appropriately.\n2. Replace `time.sleep` in `ai_providers.py` with `asyncio.sleep` or use the `tenacity` library for retries with backoff, ensuring that the function is async.\n3. In `git_utils.py` and `terminal.py`, replace `subprocess.run` with `asyncio.create_subprocess_exec` to execute shell commands asynchronously. Ensure that the output is captured correctly using `await process.communicate()`.\n4. Make `generate_sitrep` in `scribe.py` an async function to support the changes and ensure it integrates seamlessly with the rest of the system.\n5. Update any calling code to handle the new async functions, including adding `await` where necessary.",
        "testStrategy": "1. Write unit tests for `ai_providers.py` to ensure that HTTP requests are made asynchronously and responses are handled correctly.\n2. Test retry logic using `asyncio.sleep` or `tenacity` to confirm that retries occur without blocking.\n3. Verify that `git_utils.py` and `terminal.py` execute shell commands asynchronously and capture outputs correctly.\n4. Conduct integration tests to ensure that the overall system performance improves and that no blocking occurs during AI calls.\n5. Perform manual testing to simulate AI calls and observe that the system remains responsive without freezes.",
        "status": "done",
        "dependencies": [
          "6",
          "7",
          "17"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Replace requests.post with httpx.AsyncClient.post in ai_providers.py",
            "description": "Modify the HTTP request logic in ai_providers.py to use asynchronous HTTP calls with httpx.AsyncClient.post.",
            "dependencies": [],
            "details": "Identify all instances of requests.post in ai_providers.py. Replace them with httpx.AsyncClient.post. Ensure that the surrounding function is converted to an async function and that the response is handled using await. Update any related error handling and logging to work with the async context.",
            "status": "done",
            "testStrategy": "Write unit tests to verify that HTTP requests are made correctly and responses are handled as expected in an asynchronous manner.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Replace time.sleep with asyncio.sleep in ai_providers.py",
            "description": "Convert blocking sleep calls to non-blocking using asyncio.sleep or implement retry logic with tenacity for backoff.",
            "dependencies": [
              1
            ],
            "details": "Locate all instances of time.sleep in ai_providers.py. Replace them with asyncio.sleep to ensure non-blocking behavior. If retry logic is needed, use the tenacity library to implement retries with exponential backoff. Ensure that the functions using these calls are async.",
            "status": "done",
            "testStrategy": "Test the functions to ensure they behave correctly with non-blocking sleep and retry logic, verifying that the application does not freeze during these operations.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Make generate_sitrep in scribe.py an async function",
            "description": "Convert the generate_sitrep function in scribe.py to an async function to support asynchronous operations.",
            "dependencies": [
              1,
              2
            ],
            "details": "Modify the generate_sitrep function to be async. Ensure that all internal calls within this function that can be async are awaited. Update any calling code to handle the async nature of this function, including adding await where necessary.",
            "status": "done",
            "testStrategy": "Test the integration of generate_sitrep with other parts of the system to ensure it functions correctly as an async function.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Replace subprocess.run with asyncio.create_subprocess_exec in git_utils.py and terminal.py",
            "description": "Update shell command execution to be asynchronous by using asyncio.create_subprocess_exec.",
            "dependencies": [
              1,
              2
            ],
            "details": "Identify all instances of subprocess.run in git_utils.py and terminal.py. Replace them with asyncio.create_subprocess_exec. Ensure that the output is captured correctly using await process.communicate(). Convert the surrounding functions to async if necessary.",
            "status": "done",
            "testStrategy": "Verify that shell commands execute correctly and asynchronously, capturing output as expected. Ensure that the application remains responsive during these operations.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Update freeze_logic to properly await all async calls",
            "description": "Ensure that all calls to async functions are properly awaited in freeze_logic and that the daemon watchdog can process events during async AI calls.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Review the freeze_logic to identify all async function calls. Ensure that each call is properly awaited. Verify that the daemon watchdog is capable of processing events concurrently with async AI operations, making adjustments as necessary to the event loop or task management.",
            "status": "done",
            "testStrategy": "Conduct integration tests to ensure that the system remains responsive and that the daemon watchdog processes events correctly during asynchronous operations.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 29,
        "title": "Fix Daemon Context Awareness for IDE Environments",
        "description": "Improve the daemon's context awareness by checking for tmux sessions and IDE environments, and provide alternative context capture methods.",
        "details": "1. Modify `pd_daemon.py` to check if a tmux session exists and has active clients before attempting to capture terminal output. Use `subprocess.run(['tmux', 'has-session', '-t', session_name])` to verify session existence and `tmux list-clients` to check for active clients.\n2. If no tmux session is found or no active clients are present, skip terminal capture and log a warning instead of returning ghost data.\n3. Detect IDE environments by checking the `TERM_PROGRAM` and `VSCODE` environment variables. If detected, adjust the daemon's behavior to avoid tmux assumptions.\n4. Implement alternative context capture methods for IDE environments, such as capturing the last command from the integrated terminal or using IDE-specific APIs if available.\n<info added on 2025-12-16T00:04:13.933Z>\nImplemented daemon context awareness improvements:\n- Added IDE environment detection (TERM_PROGRAM/VSCODE) to avoid tmux assumptions.\n- Added tmux session existence and active client checks (tmux has-session + list-clients) before attempting terminal capture.\n- When terminal capture is not reliable, daemon calls freeze_logic(..., skip_terminal_capture=True) to prevent storing ghost terminal output.\n- Added skip_terminal_capture support to freeze_logic, which stores placeholder terminal context.\n- Updated tests/test_daemon.py accordingly.\nVerification: pytest -q (60 passed).\n</info added on 2025-12-16T00:04:13.933Z>",
        "testStrategy": "1. Test in a tmux environment: Ensure that the daemon correctly identifies active tmux sessions and captures terminal output only when sessions are valid.\n2. Test in an IDE environment (e.g., VS Code): Verify that the daemon detects the IDE environment using environment variables and skips tmux-specific operations.\n3. Simulate absence of tmux sessions: Confirm that the daemon logs a warning and does not attempt to capture terminal output.\n4. Check alternative context capture: In an IDE, ensure that the daemon captures the last command or relevant context from the IDE terminal.",
        "status": "done",
        "dependencies": [
          "7",
          "14",
          "28"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 30,
        "title": "Implement Interactive Freeze Protocol",
        "description": "Refactor the pd freeze command to initiate an interactive interview process instead of using a single --note flag.",
        "details": "Refactor the existing pd freeze command to default to an interactive multi-question interview. This interview will replace the current --note flag and will consist of the following questions: 1) What is the primary objective of this session? 2) What didn't work or what is the key uncertainty? 3) What is the next concrete action? 4) Optional: Any additional notes or brain dump. Update the ContextSnapshot schema in core/db.py to include new structured fields: human_objective, human_blocker, human_next_step. Ensure that the responses to these questions are stored in the database in a structured format to improve the quality of AI-generated SITREPs. Consider user experience and ensure the interview is user-friendly and intuitive.\n<info added on 2025-12-16T00:00:58.236Z>\nImplemented Interactive Freeze Protocol:\n- Extended ContextSnapshot schema with structured fields: human_objective, human_blocker, human_next_step.\n- Refactored pd freeze to run an interactive 4-question interview by default; added --no-interview to disable prompts and allow fully non-interactive usage via flags.\n- Updated freeze_logic to store structured answers in DB and pass them to scribe prompt for higher-quality SITREPs.\n- Updated scribe prompt to include Human Context when available.\n- Updated tests/test_freeze.py for new CLI flags and structured fields; full suite passes.\nVerification: pytest -q (60 passed).\n</info added on 2025-12-16T00:00:58.236Z>",
        "testStrategy": "1. Run the pd freeze command and verify that the interactive interview is initiated.\n2. Answer each question in the interview and complete the process.\n3. Check the database to ensure that the responses are stored correctly in the new structured fields: human_objective, human_blocker, human_next_step.\n4. Verify that the AI-generated SITREP uses the new structured data fields to produce a coherent summary.\n5. Conduct user testing to ensure the interview process is intuitive and user-friendly.",
        "status": "done",
        "dependencies": [
          "6",
          "7",
          "12"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 31,
        "title": "Implement Time to First Commit KPI Tracking",
        "description": "Add EventLog table to core/db.py and implement logging and reporting for Time to First Commit (TTC) metric.",
        "details": "1. Modify core/db.py to include a new table 'EventLog' with the following fields: id (primary key), timestamp (datetime), repo_id (string), event_type (enum with values SWITCH_IN, COMMIT).\n2. Instrument the 'pd switch' command to log a SWITCH_IN event to the EventLog table whenever a repository switch occurs.\n3. Create a new command 'pd install-hooks' that sets up a post-commit git hook in the repository. This hook should call a new internal command 'pd _internal-log-commit' to log a COMMIT event to the EventLog table.\n4. Implement a new command 'pd metrics' that calculates and reports the average and recent Time to First Commit (TTC) times by analyzing the EventLog entries. This command should output the TTC in a human-readable format and support filtering by repository.\n5. Ensure that the new EventLog table and logging mechanisms are integrated with existing database management and migration systems.\n<info added on 2025-12-15T23:55:35.523Z>\n- Implemented TTC KPI tracking:\n  - Added EventLog + EventType (SWITCH_IN, COMMIT) to core/db.py.\n  - Instrumented core/orchestrator.switch_logic to log SWITCH_IN on each pd switch.\n  - Implemented pd install-hooks [repo_id] to install a git post-commit hook that calls 'pd _internal-log-commit <repo_id>'.\n  - Implemented hidden command pd _internal-log-commit to log COMMIT events.\n  - Implemented pd metrics [--repo <repo_id>] to compute TTC deltas (SWITCH_IN -> next COMMIT) and report avg/recent TTC.\n  - Added/updated tests: EventLog insert in tests/test_db.py; SWITCH_IN logging in tests/test_switch.py; CLI tests for install-hooks/internal-log-commit/metrics in tests/test_cli.py.\n  - Verified: pytest tests/test_db.py tests/test_switch.py tests/test_cli.py (16 passed).\n</info added on 2025-12-15T23:55:35.523Z>",
        "testStrategy": "1. Verify that the EventLog table is created correctly in the database schema.\n2. Test the 'pd switch' command to ensure it logs a SWITCH_IN event in the EventLog table.\n3. Run 'pd install-hooks' in a test repository and verify that the post-commit hook is correctly installed.\n4. Commit changes in the test repository and check that a COMMIT event is logged in the EventLog table.\n5. Execute the 'pd metrics' command and verify that it correctly calculates and displays the average and recent TTC times.\n6. Perform end-to-end testing by switching to a repository, making a commit, and checking the metrics output for accuracy.",
        "status": "done",
        "dependencies": [
          "3",
          "12"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 32,
        "title": "Enhance pd status with Last Touched Timestamp",
        "description": "Add filesystem scanning logic to pd status to find the most recent file modification time for each repository, respecting .gitignore, and add a Last Touched column to the status table.",
        "details": "1. Modify the pd status command to include a new column 'Last Touched' which displays the most recent file modification time (mtime) for each repository.\n2. Implement a filesystem scanning function that traverses the repository directories, respecting .gitignore files, to determine the latest mtime.\n3. Use Python's os and pathlib modules to efficiently scan directories and retrieve file mtimes.\n4. Integrate this logic into the existing status command, ensuring that the Last Touched column is updated dynamically based on the latest file activity.\n5. Update the status table rendering logic to include the new column, ensuring it is displayed clearly alongside existing columns.",
        "testStrategy": "1. Create a test repository with multiple files and a .gitignore file.\n2. Modify some files and run the pd status command to verify that the Last Touched column reflects the most recent file modification times.\n3. Ensure that files listed in .gitignore are not considered in the Last Touched calculation.\n4. Test with various repository structures and file types to ensure robustness.\n5. Verify that the status table displays the Last Touched column correctly and that it updates as expected when files are modified.",
        "status": "done",
        "dependencies": [
          "1",
          "10"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 33,
        "title": "Implement Longitudinal SITREP with Deep-Dive Command",
        "description": "Develop a new command 'pd sitrep --deep-dive <repo_id>' to generate a longitudinal summary from historical ContextSnapshot records.",
        "details": "Create a new command in the CLI tool, 'pd sitrep --deep-dive <repo_id>', which retrieves the last 3-5 ContextSnapshot records from the database. These records should include structured human notes (objective, blocker, next_step) and previous AI summaries. Compile these into a historical narrative and send it to the ai_model_hq for processing. The AI model should generate a detailed longitudinal summary that outlines the problems being addressed, failed approaches, and recommended next steps. This feature is designed to address the cold start problem after long absences by providing a comprehensive overview of past activities and insights. Ensure integration with the interactive freeze protocol and tiered AI model support for seamless operation.",
        "testStrategy": "1. Create mock ContextSnapshot records in the database with varying objectives, blockers, and next steps. 2. Execute 'pd sitrep --deep-dive <repo_id>' and verify that the command retrieves the correct records. 3. Check that the compiled narrative is correctly formatted and sent to ai_model_hq. 4. Validate that the AI-generated summary accurately reflects the historical context and provides actionable next steps. 5. Test the command with different AI model configurations to ensure compatibility with tiered AI model support.",
        "status": "done",
        "dependencies": [
          "11",
          "30",
          "34"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 34,
        "title": "Implement Tiered AI Model Support",
        "description": "Add support for tiered AI models with a high-quality model configuration and command-line flag.",
        "details": "1. Update the configuration file `conf/config.yaml` to include a new field `ai_model_hq` which will specify the high-quality AI model to be used, such as 'claude-3-5-sonnet' or 'gpt-4o'.\n2. Modify the `pd freeze` command to accept a new `--hq` flag. When this flag is used, the command should utilize the high-quality model specified in the configuration for important context captures.\n3. Update the model selection logic in `core/scribe.py` to check for the `--hq` flag and switch to the high-quality model if the flag is present.\n4. Ensure that the system intelligently balances cost versus quality by defaulting to a standard model unless the `--hq` flag is explicitly set.\n5. Consider the implications of model switching on performance and cost, and document any trade-offs in the code comments.",
        "testStrategy": "1. Update `conf/config.yaml` with a test high-quality model and verify that the configuration loads correctly.\n2. Run the `pd freeze` command with and without the `--hq` flag and verify that the correct model is selected in each case by checking logs or debug output.\n3. Ensure that the `core/scribe.py` logic correctly switches models based on the presence of the `--hq` flag.\n4. Conduct performance tests to measure any impact on execution time and resource usage when using the high-quality model.\n5. Verify that the system defaults to the standard model when the `--hq` flag is not used.",
        "status": "done",
        "dependencies": [
          "6",
          "23"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Add ai_model_hq Field to Configuration",
            "description": "Update the configuration file `conf/config.yaml` to include a new field `ai_model_hq` for specifying the high-quality AI model.",
            "dependencies": [],
            "details": "Open the `conf/config.yaml` file and add a new field named `ai_model_hq`. This field should allow users to specify the high-quality AI model, such as 'claude-3-5-sonnet' or 'gpt-4o'. Ensure the field is well-documented with comments explaining its purpose.",
            "status": "done",
            "testStrategy": "Verify that the configuration file loads correctly with the new field and that the field can be set and retrieved without errors.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement --hq Flag for pd freeze Command",
            "description": "Modify the `pd freeze` command to accept a new `--hq` flag, which will trigger the use of the high-quality model specified in the configuration.",
            "dependencies": [
              1
            ],
            "details": "Update the command-line interface for `pd freeze` to recognize the `--hq` flag. Ensure that when this flag is used, the command reads the `ai_model_hq` field from the configuration and uses the specified model for processing.",
            "status": "done",
            "testStrategy": "Test the `pd freeze` command with and without the `--hq` flag to ensure it correctly switches models based on the flag.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Update Model Selection Logic in scribe.py",
            "description": "Modify the model selection logic in `core/scribe.py` to check for the `--hq` flag and switch to the high-quality model if the flag is present.",
            "dependencies": [
              2
            ],
            "details": "In `core/scribe.py`, update the logic to check if the `--hq` flag is set. If it is, the script should switch to using the model specified in the `ai_model_hq` configuration field. Ensure this logic is clear and maintainable.",
            "status": "done",
            "testStrategy": "Run unit tests to verify that the model selection logic correctly switches models based on the presence of the `--hq` flag.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Add Validation and Error Handling for HQ Model Availability",
            "description": "Implement validation and error handling to ensure the high-quality model specified is available and can be used without issues.",
            "dependencies": [
              3
            ],
            "details": "Add checks to validate that the model specified in `ai_model_hq` is available and supported by the system. Implement error handling to provide clear messages if the model is unavailable or if there are issues switching models.",
            "status": "done",
            "testStrategy": "Test with various valid and invalid model names in the `ai_model_hq` field to ensure proper validation and error messages are displayed.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Update Documentation for Tiered AI Usage",
            "description": "Document the new tiered AI model support, including configuration options and command-line usage.",
            "dependencies": [
              4
            ],
            "details": "Update the project's documentation to include instructions on setting the `ai_model_hq` field, using the `--hq` flag, and understanding the trade-offs between cost and quality. Ensure the documentation is clear and accessible to users.",
            "status": "done",
            "testStrategy": "Review the documentation for clarity and completeness. Ensure it accurately reflects the new functionality and is easy to follow.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 35,
        "title": "Enable WAL Mode for SQLite Database",
        "description": "Modify core/db.py to set SQLite journal mode to WAL (Write-Ahead Logging) instead of DELETE.",
        "details": "To enable WAL mode for the SQLite database, modify the database connection setup in core/db.py. Add the SQL command `PRAGMA journal_mode=WAL;` immediately after establishing a connection to the SQLite database. This change will help prevent database locking issues when the daemon and CLI access the database concurrently. Ensure that the connection is properly closed after operations to maintain database integrity. Review the SQLite documentation on WAL mode to understand its benefits and limitations, such as increased disk space usage and potential performance impacts.",
        "testStrategy": "1. Modify the existing database connection tests in tests/test_db.py to verify that the journal mode is set to WAL. \n2. Use a test database and execute a connection setup, then query `PRAGMA journal_mode;` to confirm it returns 'wal'. \n3. Conduct concurrent read/write operations from both the daemon and CLI to ensure no locking issues occur. \n4. Verify that the database integrity is maintained after multiple concurrent operations.",
        "status": "done",
        "dependencies": [
          "3"
        ],
        "priority": "low",
        "subtasks": []
      },
      {
        "id": 36,
        "title": "Remove Dead Configuration Code",
        "description": "Delete the unused core/registry.py, system/registry.yaml, and tests/test_registry.py files to finalize the configuration unification.",
        "details": "To complete the configuration unification, remove the following files: core/registry.py, system/registry.yaml, and tests/test_registry.py. These files are remnants of the old configuration system and are no longer needed since Hydra is now the active configuration system. Before deleting these files, conduct a thorough search across the codebase to ensure no other parts of the system depend on them. Use tools like 'grep' or IDE search functionalities to confirm that there are no references to these files. Once confirmed, safely delete the files and commit the changes.\n<info added on 2025-12-17T01:51:56.430Z>\nThe audit revealed that the task was incorrectly marked as 'done' because the files still exist on the filesystem. The required deletions include: \n\n1. prime_directive/core/registry.py (old Pydantic config)\n2. prime_directive/system/registry.yaml (old config file)\n3. main.py (unused boilerplate)\n4. prime_directive/base.py (unused)\n5. prime_directive/cli.py (unused)\n\nThis oversight creates a 'Split-Brain' configuration risk, where users might edit registry.yaml expecting results while the code uses conf/config.yaml. Ensure these files are deleted to prevent configuration inconsistencies.\n</info added on 2025-12-17T01:51:56.430Z>",
        "testStrategy": "1. Use a code search tool to verify that there are no references to core/registry.py, system/registry.yaml, and tests/test_registry.py in the codebase. 2. After deletion, run the full test suite to ensure no tests fail due to missing files. 3. Manually inspect the configuration setup to confirm that Hydra is functioning as expected without the deleted files.",
        "status": "pending",
        "dependencies": [
          "20"
        ],
        "priority": "low",
        "subtasks": [
          {
            "id": 1,
            "title": "Conduct Codebase Search for File References",
            "description": "Search the codebase for any references to the files to be deleted.",
            "dependencies": [],
            "details": "Use tools like 'grep' or IDE search functionalities to ensure no parts of the system depend on the files: core/registry.py, system/registry.yaml, main.py, prime_directive/base.py, and prime_directive/cli.py.",
            "status": "pending",
            "testStrategy": "Verify no references are found in the codebase."
          },
          {
            "id": 2,
            "title": "Review Search Results",
            "description": "Review the results from the codebase search to confirm no dependencies exist.",
            "dependencies": [
              1
            ],
            "details": "Carefully examine the search results to ensure that no parts of the codebase reference the files to be deleted. Document any findings.",
            "status": "pending",
            "testStrategy": "Ensure no false negatives in search results."
          },
          {
            "id": 3,
            "title": "Delete Unused Files",
            "description": "Safely delete the identified unused files from the codebase.",
            "dependencies": [
              2
            ],
            "details": "Remove the following files: core/registry.py, system/registry.yaml, main.py, prime_directive/base.py, and prime_directive/cli.py. Ensure they are backed up if necessary.",
            "status": "pending",
            "testStrategy": "Confirm files are removed from the filesystem."
          },
          {
            "id": 4,
            "title": "Commit Changes to Version Control",
            "description": "Commit the deletion changes to the version control system.",
            "dependencies": [
              3
            ],
            "details": "Create a commit with a message explaining the removal of unused configuration files. Push the changes to the repository.",
            "status": "pending",
            "testStrategy": "Verify commit is successful and changes are reflected in the repository."
          },
          {
            "id": 5,
            "title": "Run Full Test Suite",
            "description": "Execute the full test suite to ensure no tests fail due to the file deletions.",
            "dependencies": [
              4
            ],
            "details": "Run all existing tests to confirm that the deletion of files has not introduced any errors or failures in the system.",
            "status": "pending",
            "testStrategy": "All tests should pass without errors."
          }
        ],
        "updatedAt": "2025-12-17T01:51:39.318Z"
      },
      {
        "id": 37,
        "title": "Implement V1.2 Freeze Protocol Prompts",
        "description": "Rename SPEC doc and update CLI prompts in 'pd freeze' to match SPEC-V1.2-FREEZE-PROTOCOL.md.",
        "details": "Renamed docs/doc.md to docs/SPEC-V1.2-FREEZE-PROTOCOL.md. Updated prime_directive/bin/pd.py to use the new optimized prompts: 'Context: What was your specific focus...', 'Mental Cache...', 'The Hook...', 'Brain Dump...'. This aligns the CLI with the V1.2 design specification.",
        "testStrategy": "Verified code matches spec strings exactly.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 38,
        "title": "Deploy Documentation to GitHub Pages",
        "description": "Set up MkDocs deployment to GitHub Pages via GitHub Actions workflow.",
        "details": "Created .github/workflows/docs.yml to build and deploy MkDocs site. Configured repository to use GitHub Actions as Pages source. Site URL: https://ImmortalDemonGod.github.io/prime-directive/.",
        "testStrategy": "Verify workflow run in GitHub Actions and check deployed site URL.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 39,
        "title": "Restore CI Workflows",
        "description": "Repair CI workflows (main.yml, release.yml) by replacing invalid action versions with stable ones.",
        "details": "Replaced non-existent 'actions/checkout@v6' and 'actions/setup-python@v6' with '@v4' and '@v5' respectively in main.yml and release.yml. Verified YAML validity.",
        "testStrategy": "Verify CI workflows (linter, tests_linux, tests_mac, tests_win) appear and run in GitHub Actions tab.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 40,
        "title": "Improve CLI UX for Repo IDs",
        "description": "Enhance pd CLI to auto-fix trailing slashes in repo IDs and suggest corrections for typos.",
        "details": "Modified prime_directive/bin/pd.py to normalize repo IDs (strip trailing slashes) and use difflib for 'Did you mean?' suggestions. Updated tests/test_freeze.py to verify new behavior.",
        "testStrategy": "Run 'pd freeze prime-directive/' (should work) and 'pd freeze test-rep' (should suggest 'test-repo').",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 41,
        "title": "Fix Context Compression Failure in SITREP Generation",
        "description": "Update core/scribe.py system prompt to prioritize human strategic insights over generic tactical summaries.",
        "details": "Modify the system prompt in core/scribe.py to shift focus from a '50 words max' tactical summary to a 'Chief of Staff' style prompt. This new prompt should emphasize strategic insights and ensure that the Brain Dump and Blocker fields are preserved and highlighted. Review the existing prompt logic and adjust it to prioritize human insights and strategic context. Ensure that the changes align with the overall goal of improving the quality and relevance of the SITREP outputs.",
        "testStrategy": "1. Review the updated prompt in core/scribe.py to ensure it reflects the 'Chief of Staff' style.\n2. Generate SITREP reports using the updated prompt and verify that strategic insights are prioritized over tactical summaries.\n3. Check that the Brain Dump and Blocker fields are preserved in the output.\n4. Conduct user testing with stakeholders to gather feedback on the new prompt's effectiveness in conveying strategic insights.",
        "status": "pending",
        "dependencies": [
          "34",
          "33"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 42,
        "title": "Fix 'Tag not found' Error in Task Master MCP",
        "description": "Resolve the 'Tag not found' error by upgrading Task Master AI and Node runtime.",
        "details": "1. Use Node Version Manager (nvm) to switch to Node v20.19.6 and set it as the default version: `nvm use 20.19.6 && nvm alias default 20.19.6`.\n2. Upgrade Task Master AI to the latest version (0.38.0) globally: `npm install task-master-ai@latest -g`.\n3. Verify the Task Master AI installation by running `task-master list` to ensure it lists tasks correctly.\n4. Test MCP calls (`mcp0_get_tasks` and `mcp0_get_task`) to confirm they execute without errors.\n5. Attempt to create a task via CLI to ensure `mcp0_add_task` functions correctly.\n6. If the MCP server still reports version 0.17.0, restart the Windsurf process to reload the MCP server binary.\n<info added on 2025-12-17T01:40:36.124Z>\nStatus update: This task is not fully resolved. Completed steps include: (1) Node upgraded to v20.19.6 using nvm; (2) Task Master AI upgraded to v0.38.0 with CLI verification; (3) Successful task addition via CLI (e.g., task 41). Outstanding issue: Windsurf MCP server still operates on Task Master AI v0.17.0, as indicated by MCP responses, and `mcp0_add_task` fails. Resolution likely requires restarting Windsurf/reloading the MCP server and ensuring the MCP server uses the updated Node and Task Master AI installation. Do not mark as complete until `mcp0_add_task` succeeds.\n</info added on 2025-12-17T01:40:36.124Z>",
        "testStrategy": "1. Run `task-master list` to verify tasks are listed correctly.\n2. Execute `mcp0_get_tasks` and `mcp0_get_task` to ensure MCP calls work without errors.\n3. Use the CLI to create a new task and verify it is added successfully.\n4. If issues persist, restart the Windsurf process and repeat the tests to ensure the MCP server is updated.",
        "status": "in-progress",
        "dependencies": [
          "5",
          "9",
          "27"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-17T01:40:16.656Z"
      },
      {
        "id": 43,
        "title": "Add TERMINAL_DISCIPLINE Rule to .windsurfrules for Tmux Context Tracking",
        "description": "Implement a rule in .windsurfrules to ensure Windsurf Agent uses tmux for context tracking, preventing command execution in raw IDE shells.",
        "details": "1. **Modify .windsurfrules**: Add a new rule named TERMINAL_DISCIPLINE that checks if the current environment is a tmux session before executing terminal commands. Use the following shell snippet: `if [ -z \"$TMUX\" ]; then pd switch $(basename $(pwd)) || { [ $? -eq 88 ] && tmux attach -t pd-$(basename $(pwd)); }; fi`. This ensures that commands are executed within a tmux session, allowing proper context tracking by the Windsurf Agent.\n\n2. **Update Documentation**: Document this new rule in the projectâ€™s README or relevant documentation files, explaining its purpose and usage.\n\n3. **Integration with Existing Systems**: Ensure compatibility with existing tmux session management and context tracking mechanisms, particularly those implemented in tasks related to tmux and terminal state capture.",
        "testStrategy": "1. **Unit Test**: Create unit tests to simulate environments with and without tmux sessions. Verify that the rule correctly identifies the environment and executes the appropriate commands.\n\n2. **Integration Test**: Run integration tests to ensure that the Windsurf Agent operates correctly with the new rule in place, maintaining context tracking and SITREP generation.\n\n3. **Manual Verification**: Manually test the rule by executing commands in both tmux and non-tmux environments, ensuring that the rule enforces tmux usage as intended.",
        "status": "pending",
        "dependencies": [
          "8",
          "16",
          "29"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 44,
        "title": "Create AIV-SOP.md Documentation",
        "description": "Develop a formal Standard Operating Procedure for the AIV model, detailing verification processes for human verifiers.",
        "details": "Create a new document named AIV-SOP.md in the documentation directory. This document will outline the Standard Operating Procedure for the Architect-Implementer-Verifier (AIV) model. Include detailed sections on what verification entails for human verifiers, focusing on three main checks: \n\n1. **Clean Tree Check**: Describe the process of static verification for refactors and deletions. Emphasize the importance of manually inspecting the file tree, not just relying on `git status`, to ensure no unintended changes.\n\n2. **Runtime Check**: Explain dynamic verification by running commands with specific flags as mentioned in the specification. Provide examples of typical commands and expected outputs.\n\n3. **State Check**: Detail the procedure for data verification, especially for database schema changes. Include steps for inspecting the database to confirm that changes align with the intended design.\n\nAddress the 'winging it' problem by emphasizing the necessity of these checks to prevent the Verifier role from accepting AI claims without proper validation.",
        "testStrategy": "1. Review the AIV-SOP.md document for completeness and clarity.\n2. Ensure each verification step is clearly defined and includes examples where applicable.\n3. Conduct a peer review session with team members to validate the accuracy and practicality of the procedures outlined.\n4. Verify that the document is accessible and correctly formatted in the documentation section of the repository.",
        "status": "pending",
        "dependencies": [
          "38"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 45,
        "title": "Implement LLM Interview Mode for pd Freeze",
        "description": "Develop an LLM-based interview mode for pd freeze to ask context-specific questions during the freeze process.",
        "details": "This task involves creating a new feature within the pd freeze command that utilizes a Language Learning Model (LLM) to analyze the current state and ask the user context-specific questions. The implementation should ensure that the LLM operates asynchronously to prevent CLI hang-ups. This requires completing the Async I/O Refactor first. The LLM should be integrated to analyze the snapshot data and generate questions that help the user reflect on their current session. Consider using existing AI provider abstractions for LLM integration and ensure that the questions are stored in the database alongside other freeze data.",
        "testStrategy": "1. Verify that the LLM interview mode is initiated during the pd freeze process without causing delays.\n2. Test the asynchronous operation by simulating multiple freeze commands and ensuring no CLI hang-ups.\n3. Validate that the context-specific questions are relevant and stored correctly in the database.\n4. Conduct user testing to ensure the questions aid in session reflection and capture useful insights.",
        "status": "deferred",
        "dependencies": [
          "19",
          "23",
          "30"
        ],
        "priority": "low",
        "subtasks": [],
        "updatedAt": "2025-12-17T01:48:26.647Z"
      },
      {
        "id": 46,
        "title": "Unify Packaging: Eliminate Dependency Triangle",
        "description": "Consolidate dependency management by removing setup.py and requirements.txt, and updating pyproject.toml as the single source of truth.",
        "details": "1. Delete the setup.py file from the repository to prevent legacy tools from using outdated dependency definitions.\n2. Remove the requirements.txt file to eliminate redundancy in dependency management.\n3. Consolidate all dependencies into the pyproject.toml file, ensuring it includes all necessary packages and versions.\n4. Update the Makefile to use 'uv pip install -e .' exclusively for installing dependencies, ensuring consistency with the pyproject.toml configuration.\n5. Review CODE-AUDIT-V1.0 Sections 5.3 and 6.1 for any additional considerations or requirements related to dependency management.",
        "testStrategy": "1. Verify that setup.py and requirements.txt are removed from the repository.\n2. Check that pyproject.toml contains all necessary dependencies and correct versions.\n3. Run 'uv pip install -e .' and ensure all dependencies are installed correctly without errors.\n4. Execute a full build and test cycle to confirm that the application functions as expected with the updated dependency management.\n5. Review the Makefile changes to ensure they correctly reflect the new installation command.",
        "status": "pending",
        "dependencies": [
          1,
          22
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Remove setup.py from repository",
            "description": "Delete the setup.py file to prevent legacy tools from using outdated dependency definitions.",
            "dependencies": [],
            "details": "Navigate to the root directory of the repository and delete the setup.py file. Ensure no scripts or tools rely on it.",
            "status": "pending",
            "testStrategy": "Verify setup.py is removed and no errors occur in build scripts."
          },
          {
            "id": 2,
            "title": "Remove requirements.txt from repository",
            "description": "Eliminate redundancy by removing the requirements.txt file.",
            "dependencies": [
              1
            ],
            "details": "Locate and delete the requirements.txt file from the repository. Confirm that all dependencies are covered in pyproject.toml.",
            "status": "pending",
            "testStrategy": "Ensure requirements.txt is removed and dependencies are correctly listed in pyproject.toml."
          },
          {
            "id": 3,
            "title": "Consolidate dependencies in pyproject.toml",
            "description": "Update pyproject.toml to include all necessary packages and versions.",
            "dependencies": [
              1,
              2
            ],
            "details": "Edit the pyproject.toml file to list all dependencies previously in setup.py and requirements.txt. Ensure version accuracy.",
            "status": "pending",
            "testStrategy": "Check pyproject.toml for completeness and accuracy of dependencies."
          },
          {
            "id": 4,
            "title": "Update Makefile for dependency installation",
            "description": "Modify the Makefile to use 'uv pip install -e .' for consistent dependency installation.",
            "dependencies": [
              3
            ],
            "details": "Edit the Makefile to replace any existing dependency installation commands with 'uv pip install -e .'. Ensure it aligns with pyproject.toml.",
            "status": "pending",
            "testStrategy": "Run 'uv pip install -e .' and verify all dependencies install without errors."
          }
        ]
      },
      {
        "id": 47,
        "title": "Parallelize Freeze Logic Using asyncio.gather",
        "description": "Refactor the freeze logic to parallelize independent asynchronous operations using asyncio.gather to reduce latency.",
        "details": "In the `bin/pd.py` file, refactor the `freeze_logic` function to execute independent asynchronous operations concurrently. Replace the sequential awaits with `asyncio.gather` to run the Git status capture and terminal state capture in parallel. Specifically, create tasks for `get_status(repo_path)` and `capture_terminal_state(repo_id)`, then use `await asyncio.gather(git_task, term_task)` to execute them concurrently. This change is expected to reduce the total freeze time by 40-60% as the latency will be determined by the longest operation rather than the sum of all operations. Ensure that any exceptions are handled appropriately to maintain robustness.",
        "testStrategy": "1. Implement unit tests to verify that `freeze_logic` correctly uses `asyncio.gather` to parallelize operations.\n2. Measure the execution time of the freeze operation before and after the refactor to confirm a reduction in latency.\n3. Conduct integration tests to ensure that the freeze operation still captures the correct Git and terminal states and that these are saved correctly in the database.\n4. Perform a code review to ensure that the refactor aligns with the guidelines in CODE-AUDIT-V1.0 Sections 2.2, 5.2, and 6.3.",
        "status": "pending",
        "dependencies": [
          11,
          7
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze Current Freeze Logic",
            "description": "Review the existing freeze logic implementation in bin/pd.py.",
            "dependencies": [],
            "details": "Examine the current implementation of the freeze_logic function to understand how asynchronous operations are currently handled. Identify the parts of the code that need refactoring to use asyncio.gather.",
            "status": "pending",
            "testStrategy": "Verify understanding by documenting current flow and identifying asynchronous operations."
          },
          {
            "id": 2,
            "title": "Refactor to Use asyncio.gather",
            "description": "Modify freeze_logic to parallelize operations using asyncio.gather.",
            "dependencies": [
              1
            ],
            "details": "Refactor the freeze_logic function to replace sequential awaits with asyncio.gather. Create tasks for get_status(repo_path) and capture_terminal_state(repo_id), then use await asyncio.gather(git_task, term_task) to execute them concurrently.",
            "status": "pending",
            "testStrategy": "Implement unit tests to ensure asyncio.gather is used correctly and operations run concurrently."
          },
          {
            "id": 3,
            "title": "Implement Exception Handling",
            "description": "Ensure robust exception handling in the refactored freeze_logic function.",
            "dependencies": [
              2
            ],
            "details": "Add try-except blocks around the asyncio.gather call to handle any exceptions that may occur during the execution of the asynchronous tasks. Ensure that the function remains robust and can handle errors gracefully.",
            "status": "pending",
            "testStrategy": "Test with scenarios that trigger exceptions to verify that they are handled appropriately."
          },
          {
            "id": 4,
            "title": "Performance Testing and Validation",
            "description": "Measure performance improvements and validate functionality.",
            "dependencies": [
              2,
              3
            ],
            "details": "Conduct performance tests to measure the execution time of the freeze operation before and after the refactor. Validate that the refactored function reduces latency as expected. Perform integration tests to ensure overall functionality remains intact.",
            "status": "pending",
            "testStrategy": "Compare execution times before and after refactor. Conduct integration tests to confirm correct operation."
          }
        ]
      },
      {
        "id": 48,
        "title": "Harden Shell Wrapper: Check for tmux Binary",
        "description": "Update shell_integration.zsh to check for the tmux binary before attempting to attach a session, providing a clean error message if tmux is missing.",
        "details": "Modify the shell_integration.zsh script to include a pre-check for the tmux binary using a command like `command -v tmux` or `which tmux`. If the tmux binary is not found, output a user-friendly error message and exit gracefully. This prevents the script from failing with 'command not found' errors when tmux is not installed. Ensure that the error handling logic is robust and does not interfere with other parts of the script.",
        "testStrategy": "1. Temporarily remove or rename the tmux binary on a test system.\n2. Run the shell_integration.zsh script and verify that it outputs a clear error message indicating that tmux is not installed.\n3. Restore the tmux binary and rerun the script to ensure normal operation resumes.\n4. Check that the script exits gracefully without affecting other functionalities when tmux is missing.",
        "status": "pending",
        "dependencies": [
          10,
          16,
          26
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Add tmux Binary Check to Script",
            "description": "Modify shell_integration.zsh to check for the tmux binary before attaching a session.",
            "dependencies": [],
            "details": "Use `command -v tmux` to check if tmux is installed. If not, output an error message and exit.",
            "status": "pending",
            "testStrategy": "Temporarily remove tmux and run the script to ensure the error message is displayed."
          },
          {
            "id": 2,
            "title": "Implement Error Handling Logic",
            "description": "Ensure the script exits gracefully with a user-friendly error message if tmux is not found.",
            "dependencies": [
              1
            ],
            "details": "Add logic to handle the absence of tmux without affecting other script parts. Use `echo` for error messages.",
            "status": "pending",
            "testStrategy": "Run the script without tmux and verify the error message is clear and the script exits gracefully."
          },
          {
            "id": 3,
            "title": "Verify Script Integration",
            "description": "Test the integration of the tmux check with the rest of the script to ensure no interference.",
            "dependencies": [
              1,
              2
            ],
            "details": "Ensure the tmux check does not interfere with other functionalities of shell_integration.zsh.",
            "status": "pending",
            "testStrategy": "Run the script with and without tmux installed to verify normal operation and error handling."
          }
        ]
      },
      {
        "id": 49,
        "title": "Refactor Daemon Loop to Use asyncio.sleep",
        "description": "Modify the daemon loop in pd_daemon.py to use 'await asyncio.sleep(interval)' instead of 'time.sleep(interval)' to prevent blocking the event loop.",
        "details": "In the pd_daemon.py file, locate the main loop where 'time.sleep(interval)' is currently used. Replace this with 'await asyncio.sleep(interval)' to ensure the event loop remains responsive. This change will allow the daemon to process other signals and shut down gracefully while the freeze_logic is running asynchronously. Refer to CODE-AUDIT-V1.0 Sections 5.4 and 6.5 for additional context and guidelines on maintaining a healthy event loop.",
        "testStrategy": "1. Modify the daemon loop to use 'await asyncio.sleep(interval)'.\n2. Run the daemon and initiate the freeze_logic asynchronously.\n3. Verify that the daemon can process other signals and shut down gracefully during the freeze operation.\n4. Conduct stress tests to ensure the event loop remains responsive under load.",
        "status": "pending",
        "dependencies": [
          11,
          47
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Identify and Replace time.sleep with asyncio.sleep",
            "description": "Locate the main loop in pd_daemon.py and replace time.sleep with await asyncio.sleep.",
            "dependencies": [],
            "details": "Open pd_daemon.py and find the main loop where time.sleep(interval) is used. Replace it with await asyncio.sleep(interval) to prevent blocking the event loop.",
            "status": "pending",
            "testStrategy": "Run the daemon and ensure it remains responsive during the sleep interval."
          },
          {
            "id": 2,
            "title": "Update Daemon to Handle Asynchronous Signals",
            "description": "Modify the daemon to handle signals asynchronously while using asyncio.sleep.",
            "dependencies": [
              1
            ],
            "details": "Ensure the daemon can process other signals and shut down gracefully while using asyncio.sleep. This involves updating signal handling to be compatible with asynchronous operations.",
            "status": "pending",
            "testStrategy": "Test signal handling by sending various signals to the daemon and observing its behavior."
          },
          {
            "id": 3,
            "title": "Conduct Stress Tests on Event Loop",
            "description": "Perform stress tests to ensure the event loop remains responsive with asyncio.sleep.",
            "dependencies": [
              1,
              2
            ],
            "details": "Conduct stress tests by simulating high load and ensuring the event loop remains responsive. Verify that the daemon can handle multiple asynchronous tasks without blocking.",
            "status": "pending",
            "testStrategy": "Run stress tests with multiple asynchronous tasks and verify responsiveness and stability of the event loop."
          }
        ]
      },
      {
        "id": 50,
        "title": "Implement Accurate Token Counting with tiktoken",
        "description": "Replace the heuristic token counting in core/scribe.py with the tiktoken library for precise API billing alignment.",
        "details": "1. Remove the current heuristic calculation 'output_tokens = len(result.split()) * 1.3' from core/scribe.py.\n2. Integrate the tiktoken library to accurately count tokens. Install the library if not already included in the project dependencies.\n3. Modify the relevant functions to use tiktoken for token counting. Ensure that the library is correctly initialized and utilized to count tokens in the input and output text.\n4. Where possible, retrieve exact token usage from API response headers or body, specifically using 'usage.prompt_tokens' and 'usage.completion_tokens' fields returned by OpenAI APIs.\n5. Update any related documentation to reflect the changes in token counting methodology.",
        "testStrategy": "1. Write unit tests to verify that token counting using tiktoken matches expected values for a variety of input and output scenarios.\n2. Simulate API responses with 'usage.prompt_tokens' and 'usage.completion_tokens' fields and ensure that these values are correctly extracted and used.\n3. Compare the token counts from tiktoken with the heuristic method to confirm improved accuracy.\n4. Conduct integration tests to ensure that the changes do not affect other parts of the system relying on token counts.",
        "status": "pending",
        "dependencies": [
          6,
          17
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Remove Heuristic Token Calculation",
            "description": "Remove the heuristic token calculation from core/scribe.py.",
            "dependencies": [],
            "details": "Locate and remove the line 'output_tokens = len(result.split()) * 1.3' in core/scribe.py.",
            "status": "pending",
            "testStrategy": "Ensure no errors occur after removal."
          },
          {
            "id": 2,
            "title": "Integrate tiktoken Library",
            "description": "Install and integrate the tiktoken library for token counting.",
            "dependencies": [
              1
            ],
            "details": "Add tiktoken to the project dependencies and import it in core/scribe.py.",
            "status": "pending",
            "testStrategy": "Verify installation by importing tiktoken without errors."
          },
          {
            "id": 3,
            "title": "Modify Functions to Use tiktoken",
            "description": "Update functions to use tiktoken for accurate token counting.",
            "dependencies": [
              2
            ],
            "details": "Replace existing token counting logic with tiktoken's methods in core/scribe.py.",
            "status": "pending",
            "testStrategy": "Write unit tests to compare tiktoken counts with expected values."
          },
          {
            "id": 4,
            "title": "Retrieve and Use API Token Usage",
            "description": "Retrieve token usage from API responses and update logic accordingly.",
            "dependencies": [
              3
            ],
            "details": "Modify code to extract 'usage.prompt_tokens' and 'usage.completion_tokens' from API responses.",
            "status": "pending",
            "testStrategy": "Simulate API responses and verify token usage extraction."
          }
        ]
      },
      {
        "id": 51,
        "title": "Update Installation Guide with Shell Integration Step",
        "description": "Enhance the README.md to include a mandatory shell integration step for proper terminal session switching.",
        "details": "1. **Add Shell Integration Step**: Update the README.md to include a new step instructing users to add `source /path/to/prime_directive/system/shell_integration.zsh` to their `.zshrc` file. This ensures that the shell integration is sourced correctly, allowing the `pd switch` command to function as intended.\n\n2. **Explain Exit Code 88 Protocol**: Include a section explaining the significance of Exit Code 88. This protocol is used to signal the shell to trap and execute necessary commands for terminal session switching, aiding in debugging and understanding the process flow.\n\n3. **Document Split-Process Architecture**: Provide a detailed explanation of the split-process architecture, where the client `pd` triggers an Exit 88, and the shell traps this to run tmux commands. Reference DOC-AUDIT-V1.0 Sections 3.1 and 5.1 for further details.",
        "testStrategy": "1. **Documentation Review**: Ensure the README.md includes the new shell integration step and explanations clearly and accurately.\n2. **Functional Test**: Follow the updated installation guide on a fresh environment to verify that the `pd switch` command works correctly with the shell integration.\n3. **Debugging Verification**: Simulate a failure scenario and confirm that the Exit Code 88 explanation aids in troubleshooting.\n4. **Peer Review**: Conduct a peer review session to validate the clarity and completeness of the documentation updates.",
        "status": "pending",
        "dependencies": [
          26,
          48
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Add Shell Integration Step to README.md",
            "description": "Update the README.md to include a shell integration step for .zshrc.",
            "dependencies": [],
            "details": "Add instructions to include `source /path/to/prime_directive/system/shell_integration.zsh` in the `.zshrc` file.",
            "status": "pending",
            "testStrategy": "Verify the README.md includes the shell integration step and test in a fresh environment."
          },
          {
            "id": 2,
            "title": "Explain Exit Code 88 Protocol in README.md",
            "description": "Include a section in the README.md explaining Exit Code 88.",
            "dependencies": [
              1
            ],
            "details": "Document the significance of Exit Code 88 for terminal session switching and debugging.",
            "status": "pending",
            "testStrategy": "Ensure the explanation is clear and accurate in the README.md."
          },
          {
            "id": 3,
            "title": "Document Split-Process Architecture in README.md",
            "description": "Provide a detailed explanation of the split-process architecture in the README.md.",
            "dependencies": [
              2
            ],
            "details": "Explain how the client `pd` triggers Exit 88 and the shell traps it to run tmux commands. Reference DOC-AUDIT-V1.0 Sections 3.1 and 5.1.",
            "status": "pending",
            "testStrategy": "Check that the architecture is documented clearly with references."
          },
          {
            "id": 4,
            "title": "Review and Test Updated Installation Guide",
            "description": "Review the updated README.md and test the installation process.",
            "dependencies": [
              3
            ],
            "details": "Conduct a thorough review of the README.md and follow the installation steps to ensure functionality.",
            "status": "pending",
            "testStrategy": "Perform a functional test by following the guide on a fresh environment to verify the `pd switch` command works."
          }
        ]
      },
      {
        "id": 52,
        "title": "Sanitize Configuration: Remove Hardcoded User Paths",
        "description": "Remove hardcoded user-specific paths from config.yaml and replace them with generic placeholders.",
        "details": "1. Open the default config file at conf/config.yaml and identify all instances of hardcoded paths like '/Users/tomriddle1/prime-directive'.\n2. Replace these paths with generic placeholders using '~' for home directory expansion or environment variables such as $HOME or $USER.\n3. Update the documentation to instruct users to copy the default config to ~/.prime-directive/config.yaml.\n4. Modify pd.py to ensure it loads configuration from the user's home directory, specifically ~/.prime-directive/config.yaml.\n5. Reference DOC-AUDIT-V1.0 Section 3.1 and 5.2-5.3 for additional context and requirements.",
        "testStrategy": "1. Verify that conf/config.yaml no longer contains any hardcoded user paths.\n2. Test that the application correctly expands '~' and environment variables to the user's home directory.\n3. Ensure that pd.py successfully loads the configuration from ~/.prime-directive/config.yaml.\n4. Review the updated documentation to confirm it accurately guides users on setting up their configuration.\n5. Run the application as a different user to ensure no runtime crashes occur due to path issues.",
        "status": "pending",
        "dependencies": [
          36
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Identify Hardcoded Paths in config.yaml",
            "description": "Open conf/config.yaml and identify all hardcoded user-specific paths.",
            "dependencies": [],
            "details": "Search for paths like '/Users/tomriddle1/prime-directive' in conf/config.yaml.",
            "status": "pending",
            "testStrategy": "Verify all hardcoded paths are identified."
          },
          {
            "id": 2,
            "title": "Replace Hardcoded Paths with Placeholders",
            "description": "Replace identified paths with generic placeholders using '~' or environment variables.",
            "dependencies": [
              1
            ],
            "details": "Use '~' for home directory or $HOME/$USER for environment variables.",
            "status": "pending",
            "testStrategy": "Ensure no hardcoded paths remain and placeholders are correctly used."
          },
          {
            "id": 3,
            "title": "Update Documentation for Configuration Setup",
            "description": "Update documentation to guide users on copying config to ~/.prime-directive/config.yaml.",
            "dependencies": [
              2
            ],
            "details": "Modify documentation to include steps for copying the config file to the user's home directory.",
            "status": "pending",
            "testStrategy": "Review documentation for accuracy and clarity."
          },
          {
            "id": 4,
            "title": "Modify pd.py to Load User Configuration",
            "description": "Ensure pd.py loads configuration from ~/.prime-directive/config.yaml.",
            "dependencies": [
              2
            ],
            "details": "Update pd.py to read configuration from the user's home directory.",
            "status": "pending",
            "testStrategy": "Test that pd.py correctly loads the configuration from the specified path."
          }
        ]
      },
      {
        "id": 53,
        "title": "Comprehensive Documentation Update: Quick Start and Command Reference",
        "description": "Revise the Quick Start guide and Command Reference to reflect current CLI workflows and document all features.",
        "details": "1. **Quick Start Guide Update**: Rewrite the Quick Start guide to accurately describe the Interactive Interview Protocol, detailing the 4-step wizard process (Context, Mental Cache, Hook, Brain Dump). Include instructions for using the '--note' flag and '--no-interview' option.\n\n2. **Command Reference Expansion**: Add detailed documentation for all CLI commands, including 'pd sitrep --deep-dive', 'pd metrics', 'pd ai-usage', 'pd install-hooks', and 'pd freeze --hq'. Ensure each command's functionality, options, and examples are clearly explained.\n\n3. **CLI Help Text Update**: Update the internal docstrings in 'bin/pd.py' to reflect the current command options and workflows, correcting any outdated information, especially regarding the '--note' flag.\n\n4. **Source Reference**: Use DOC-AUDIT-V1.0 Section 3.2-3.3 and 5.4-5.5 as the primary source for identifying undocumented features and ensuring accuracy.",
        "testStrategy": "1. **Documentation Review**: Conduct a thorough review of the updated Quick Start guide and Command Reference to ensure accuracy and completeness.\n\n2. **Functional Verification**: Execute each documented command in a test environment to verify that the documentation aligns with actual functionality.\n\n3. **Peer Review**: Have a team member review the documentation for clarity and comprehensiveness.\n\n4. **Docstring Validation**: Run the CLI with '--help' to ensure all help text is updated and accurate.",
        "status": "pending",
        "dependencies": [
          10,
          33,
          11
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Revise Quick Start Guide",
            "description": "Rewrite the Quick Start guide to describe the Interactive Interview Protocol.",
            "dependencies": [],
            "details": "Detail the 4-step wizard process: Context, Mental Cache, Hook, Brain Dump. Include '--note' flag and '--no-interview' option.",
            "status": "pending",
            "testStrategy": "Review for accuracy and completeness."
          },
          {
            "id": 2,
            "title": "Expand Command Reference",
            "description": "Add detailed documentation for all CLI commands.",
            "dependencies": [
              1
            ],
            "details": "Document 'pd sitrep --deep-dive', 'pd metrics', 'pd ai-usage', 'pd install-hooks', 'pd freeze --hq'. Include functionality, options, and examples.",
            "status": "pending",
            "testStrategy": "Verify command documentation matches actual functionality."
          },
          {
            "id": 3,
            "title": "Update CLI Help Text",
            "description": "Update internal docstrings in 'bin/pd.py'.",
            "dependencies": [
              2
            ],
            "details": "Ensure docstrings reflect current command options and workflows, correcting outdated information, especially for '--note' flag.\n<info added on 2025-12-17T02:02:59.244Z>\nReview CodeRabbit generated docstrings to ensure they reflect the new Optional arguments and the Interactive Interview protocol instead of the old mandatory --note flag.\n</info added on 2025-12-17T02:02:59.244Z>",
            "status": "pending",
            "testStrategy": "Check docstrings against current CLI options."
          },
          {
            "id": 4,
            "title": "Conduct Source Reference Audit",
            "description": "Use DOC-AUDIT-V1.0 to identify undocumented features.",
            "dependencies": [
              3
            ],
            "details": "Refer to sections 3.2-3.3 and 5.4-5.5 to ensure all features are documented accurately.",
            "status": "pending",
            "testStrategy": "Cross-reference documentation with source audit."
          },
          {
            "id": 5,
            "title": "Finalize Documentation Update",
            "description": "Complete and finalize all documentation updates.",
            "dependencies": [
              4
            ],
            "details": "Ensure all sections are cohesive and reflect the latest CLI workflows and features.",
            "status": "pending",
            "testStrategy": "Conduct a comprehensive review and peer validation."
          }
        ]
      },
      {
        "id": 54,
        "title": "Update Containerfile to Match Python Version Requirement",
        "description": "Modify the Containerfile to use Python 3.11-slim to align with the project's Python version requirement specified in pyproject.toml.",
        "details": "1. Open the Containerfile and locate the line specifying the base image version, currently 'FROM python:3.7-slim'.\n2. Update this line to 'FROM python:3.11-slim' to match the 'requires-python = >=3.11' requirement in pyproject.toml.\n3. Review the rest of the Containerfile to ensure compatibility with the current project structure, including any dependencies or scripts that may be affected by the Python version change.\n4. Verify that all dependencies listed in pyproject.toml are compatible with Python 3.11 and update any that are not.\n5. Document any changes made to the Containerfile and any additional considerations for future updates.",
        "testStrategy": "1. Build the Docker image using the updated Containerfile and ensure there are no build errors related to the Python version.\n2. Run the container and execute a basic script to verify that Python 3.11 is correctly installed and functioning.\n3. Check that all project dependencies are correctly installed and operational within the container.\n4. Conduct a review of the Containerfile to ensure all changes are documented and align with project requirements.",
        "status": "pending",
        "dependencies": [
          53
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Base Image in Containerfile",
            "description": "Change the base image in the Containerfile to Python 3.11-slim.",
            "dependencies": [],
            "details": "Open the Containerfile and locate the line specifying the base image version, currently 'FROM python:3.7-slim'. Update this line to 'FROM python:3.11-slim' to match the 'requires-python = >=3.11' requirement in pyproject.toml.",
            "status": "pending",
            "testStrategy": "Build the Docker image and ensure there are no build errors related to the Python version."
          },
          {
            "id": 2,
            "title": "Review Containerfile for Compatibility",
            "description": "Ensure the rest of the Containerfile is compatible with Python 3.11.",
            "dependencies": [
              1
            ],
            "details": "Review the Containerfile to ensure compatibility with the current project structure, including any dependencies or scripts that may be affected by the Python version change.",
            "status": "pending",
            "testStrategy": "Run the container and execute a basic script to verify that Python 3.11 is correctly installed and functioning."
          },
          {
            "id": 3,
            "title": "Verify Dependency Compatibility",
            "description": "Check that all dependencies in pyproject.toml are compatible with Python 3.11.",
            "dependencies": [
              2
            ],
            "details": "Verify that all dependencies listed in pyproject.toml are compatible with Python 3.11 and update any that are not. Document any changes made to the Containerfile and any additional considerations for future updates.",
            "status": "pending",
            "testStrategy": "Check that all project dependencies are correctly installed and functioning with Python 3.11."
          }
        ]
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-12-17T01:51:39.325Z",
      "taskCount": 45,
      "completedCount": 37,
      "tags": [
        "master"
      ],
      "created": "2025-12-17T01:51:53.414Z",
      "description": "Tasks for master context",
      "updated": "2025-12-17T01:58:36.312Z"
    }
  }
}